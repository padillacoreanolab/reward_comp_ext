{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c3a02adc9e884466bc8c79db549cc3d2",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 17,
      "type": "marks"
     }
    ]
   },
   "source": [
    "# SLEAP Distance Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4546bee655b14a5dbf393161f1228e60",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Brief 1-2 sentence description of notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#calling it a second time may prevent some graphics errors\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import git\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "03b495cefa6a4798a44c7f2e4c6a3ea7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 21,
    "execution_start": 1691424003626,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports of all used packages and libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "# import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy import stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "git_repo = git.Repo(\".\", search_parent_directories=True)\n",
    "git_root = git_repo.git.rev_parse(\"--show-toplevel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "git_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.join(git_root, 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import utilities.helper\n",
    "import sleap.process_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import imageio\n",
    "# import hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2  \n",
    "from PIL import Image  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sns.set('notebook', 'ticks', font_scale=1.2)\n",
    "mpl.rcParams['figure.figsize'] = [15,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # based on each subjects individually\n",
    "# features_columns = ['subject_thorax_velocity', 'agent_thorax_velocity',\n",
    "#        'subject_thorax_to_agent_thorax', 'subject_nose_to_reward_port',\n",
    "#        'agent_nose_to_reward_port', 'subject_to_reward_port_angle',\n",
    "#        'agent_to_reward_port_angle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_difference = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing_window = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_columns = ['frame_index',\n",
    "                    ## Distance metrics\n",
    "                    'subject_thorax_to_agent_thorax',\n",
    "                    'nose_to_reward_port_sum',\n",
    "                    'nose_to_reward_port_diff',\n",
    "                    ## Velocity and speed metrics\n",
    "                    'thorax_velocity_sum', \n",
    "                    'thorax_velocity_diff',\n",
    "                    ## Orientation and angle\n",
    "                    'to_reward_port_angle_sum',\n",
    "                    'to_reward_port_angle_diff', \n",
    "                    # Individual features\n",
    "                    'subject_nose_to_reward_port',\n",
    "                    'subject_thorax_velocity',\n",
    "                    'subject_to_reward_port_angle',\n",
    "                    'agent_nose_to_reward_port',\n",
    "                    'agent_thorax_velocity',\n",
    "                    'agent_to_reward_port_angle',\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_columns = ['frame_index',\n",
    "                    ## Distance metrics\n",
    "                    'subject_thorax_to_agent_thorax',\n",
    "                    'nose_to_reward_port_sum',\n",
    "                    'nose_to_reward_port_diff',\n",
    "                    'nose_to_tail_sum',\n",
    "                    'nose_to_tail_diff',\n",
    "                    ## Velocity and speed metrics\n",
    "                    'thorax_velocity_sum', \n",
    "                    'thorax_velocity_diff',\n",
    "                    ## Orientation and angle\n",
    "                    'to_reward_port_angle_sum',\n",
    "                    'to_reward_port_angle_diff', \n",
    "                    # Individual features\n",
    "                    'subject_nose_to_reward_port',\n",
    "                    'subject_thorax_velocity',\n",
    "                    'subject_to_reward_port_angle',\n",
    "                    'agent_nose_to_reward_port',\n",
    "                    'agent_thorax_velocity',\n",
    "                    'agent_to_reward_port_angle',\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important_features_columns = ['subject_nose_to_reward_port', 'agent_nose_to_reward_port']\n",
    "# important_features_columns = [\"nose_to_reward_port_sum\", \"nose_to_reward_port_diff\", \"subject_thorax_to_agent_thorax\"]\n",
    "important_features_columns =[\n",
    "## Distance metrics\n",
    "                    'subject_thorax_to_agent_thorax',\n",
    "                    'nose_to_reward_port_sum',\n",
    "                    'nose_to_reward_port_diff',\n",
    "                    ## Velocity and speed metrics\n",
    "                    'thorax_velocity_sum', \n",
    "                    'thorax_velocity_diff',\n",
    "                    ## Orientation and angle\n",
    "                    'to_reward_port_angle_sum',\n",
    "                    'to_reward_port_angle_diff',]\n",
    "\n",
    "scaler = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "\n",
    "def nan_helper(y):\n",
    "    \"\"\"Helper to handle indices and logical indices of NaNs.\n",
    "\n",
    "    Input:\n",
    "        - y, 1d numpy array with possible NaNs\n",
    "    Output:\n",
    "        - nans, logical indices of NaNs\n",
    "        - index, a function, with signature indices= index(logical_indices),\n",
    "          to convert logical indices of NaNs to 'equivalent' indices\n",
    "    Example:\n",
    "        >>> # linear interpolation of NaNs\n",
    "        >>> nans, x= nan_helper(y)\n",
    "        >>> y[nans]= np.interp(x(nans), x(~nans), y[~nans])\n",
    "    \"\"\"\n",
    "\n",
    "    return np.isnan(y), lambda z: z.nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def interpolate_nans_in_1d_arr(arr):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    copy_arr = arr.copy()\n",
    "    nans, x= nan_helper(copy_arr)\n",
    "    copy_arr[nans] = np.interp(x(nans), x(~nans), copy_arr[~nans])\n",
    "    return copy_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bools_to_int(row):\n",
    "    # Convert boolean to integer, then to string, and join to form a binary number string\n",
    "    binary_string = ''.join(row.astype(int).astype(str))\n",
    "    # Convert binary string to a decimal integer\n",
    "    return int(binary_string, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angles_from_arrays(A, B, C, D):\n",
    "    \"\"\"\n",
    "    Calculate the angles between vectors AB and CD for arrays of 2D points.\n",
    "\n",
    "    Parameters:\n",
    "    - A, B, C, D: Each is a 2D numpy array where each row represents a point in 2D space.\n",
    "                  A and B represent points defining the first vector, AB, and C and D represent points defining the second vector, CD.\n",
    "\n",
    "    Returns:\n",
    "    - A numpy array of angles in degrees between the vectors AB and CD for each set of points.\n",
    "    \"\"\"\n",
    "    # Ensure input arrays are numpy arrays\n",
    "    A, B, C, D = map(np.array, [A, B, C, D])\n",
    "\n",
    "    # Calculate vectors AB and CD\n",
    "    AB = B - A\n",
    "    CD = D - C\n",
    "\n",
    "    # Calculate dot products and magnitudes for each pair of vectors\n",
    "    dot_products = np.einsum('ij,ij->i', AB, CD)\n",
    "    norms_AB = np.linalg.norm(AB, axis=1)\n",
    "    norms_CD = np.linalg.norm(CD, axis=1)\n",
    "\n",
    "    # Calculate cosine of the angle using the dot product and magnitudes\n",
    "    cos_angles = dot_products / (norms_AB * norms_CD)\n",
    "    \n",
    "    # Clip values to prevent domain errors due to numerical issues\n",
    "    cos_angles = np.clip(cos_angles, -1.0, 1.0)\n",
    "\n",
    "    # Calculate angles in radians and then convert to degrees\n",
    "    angles_radians = np.arccos(cos_angles)\n",
    "    angles_degrees = np.degrees(angles_radians)\n",
    "\n",
    "    return angles_degrees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_frames(video_path, frame_numbers, output_folder, max_width=640):\n",
    "    \"\"\"\n",
    "    Extracts frames from a video at specific frame numbers and saves them as images.\n",
    "\n",
    "    Parameters:\n",
    "        video_path (str): Path to the video file.\n",
    "        frame_numbers (list): List of frame numbers to extract.\n",
    "        output_folder (str): Directory to save the frames.\n",
    "        max_width (int): Maximum width of the frames. Height is adjusted proportionally.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return []\n",
    "\n",
    "    frame_paths = []\n",
    "    frame_numbers = [int(num) for num in frame_numbers]\n",
    "    frame_ids = set(frame_numbers)\n",
    "    current_frame = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if current_frame in frame_ids:\n",
    "            # Resize frame if necessary\n",
    "            height, width = frame.shape[:2]\n",
    "            if width > max_width:\n",
    "                scaling_factor = max_width / float(width)\n",
    "                new_dimensions = (max_width, int(height * scaling_factor))\n",
    "                frame = cv2.resize(frame, new_dimensions, interpolation=cv2.INTER_AREA)\n",
    "            \n",
    "            frame_path = os.path.join(output_folder, \"frame_{:05d}.png\".format(current_frame))\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            frame_paths.append(frame_path)\n",
    "            # print(f\"Extracted frame {current_frame}\")\n",
    "        \n",
    "        current_frame += 1\n",
    "    \n",
    "    cap.release()\n",
    "    return frame_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_video(frame_paths, output_folder, video_name=\"output.avi\", fps=15):\n",
    "    \"\"\"\n",
    "    Creates a video from a list of image frames.\n",
    "\n",
    "    Parameters:\n",
    "        frame_paths (list): List of paths to the frame images.\n",
    "        output_folder (str): Directory to save the video.\n",
    "        video_name (str): Filename for the video.\n",
    "        fps (int): Frames per second for the video.\n",
    "    \"\"\"\n",
    "    if not frame_paths:\n",
    "        print(\"No frames to make a video.\")\n",
    "        return\n",
    "\n",
    "    frame = cv2.imread(frame_paths[0])\n",
    "    height, width, layers = frame.shape\n",
    "\n",
    "    video_path = os.path.join(output_folder, video_name)\n",
    "    video = cv2.VideoWriter(video_path, cv2.VideoWriter_fourcc(*'DIVX'), fps, (width, height))\n",
    "\n",
    "    for frame_path in frame_paths:\n",
    "        video.write(cv2.imread(frame_path))\n",
    "\n",
    "    video.release()\n",
    "    print(f\"Video saved to {video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames_and_make_video(video_path, frame_numbers, output_folder, video_name=\"output.gif\", fps=25, max_width=640):\n",
    "    \"\"\"\n",
    "    Extracts frames from a video at specific frame numbers, resizes them, and creates a GIF from those frames.\n",
    "\n",
    "    Parameters:\n",
    "        video_path (str): Path to the video file.\n",
    "        frame_numbers (list): List of frame numbers to extract.\n",
    "        output_folder (str): Directory to save the frames and GIF.\n",
    "        gif_name (str): Filename for the GIF.\n",
    "        fps (int): Frames per second for the GIF.\n",
    "        max_width (int): Maximum width of the frames in the GIF. Height is adjusted proportionally.\n",
    "    \"\"\"\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Initialize video capture\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    # Prepare to extract frames\n",
    "    frames = []\n",
    "    frame_ids = set(frame_numbers)  # Convert list to set for faster lookup\n",
    "    current_frame = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        if current_frame in frame_ids:\n",
    "            # Resize frame to reduce GIF size\n",
    "            height, width = frame.shape[:2]\n",
    "            scaling_factor = max_width / float(width)\n",
    "            if width > max_width:  # Only resize if the image is wider than the max width\n",
    "                new_dim = (max_width, int(height * scaling_factor))\n",
    "                frame = cv2.resize(frame, new_dim, interpolation=cv2.INTER_AREA)\n",
    "            \n",
    "            frame_path = os.path.join(output_folder, f\"frame_{current_frame}.png\")\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            frames.append(frame_path)\n",
    "            print(f\"Extracted frame {current_frame}\")\n",
    "        \n",
    "        current_frame += 1\n",
    "    \n",
    "    # Close video file\n",
    "    cap.release()\n",
    "\n",
    "    frame = cv2.imread(frames[0]) \n",
    "  \n",
    "    # setting the frame width, height width \n",
    "    # the width, height of first image \n",
    "    height, width, layers = frame.shape   \n",
    "  \n",
    "    video = cv2.VideoWriter(os.path.join(output_folder, video_name), 0, fps, (width, height))  \n",
    "  \n",
    "    # Appending the images to the video one by one \n",
    "    for image in frames:  \n",
    "        video.write(cv2.imread(image))  \n",
    "      \n",
    "    # Deallocating memories taken for window creation \n",
    "    cv2.destroyAllWindows()  \n",
    "    video.release()  # releasing the video generated \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames_and_make_gif(video_path, frame_numbers, output_folder, gif_name=\"output.gif\", fps=25, max_width=640):\n",
    "    \"\"\"\n",
    "    Extracts frames from a video at specific frame numbers, resizes them, and creates a GIF from those frames.\n",
    "\n",
    "    Parameters:\n",
    "        video_path (str): Path to the video file.\n",
    "        frame_numbers (list): List of frame numbers to extract.\n",
    "        output_folder (str): Directory to save the frames and GIF.\n",
    "        gif_name (str): Filename for the GIF.\n",
    "        fps (int): Frames per second for the GIF.\n",
    "        max_width (int): Maximum width of the frames in the GIF. Height is adjusted proportionally.\n",
    "    \"\"\"\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Initialize video capture\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    # Prepare to extract frames\n",
    "    frames = []\n",
    "    frame_ids = set(frame_numbers)  # Convert list to set for faster lookup\n",
    "    current_frame = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        if current_frame in frame_ids:\n",
    "            # Resize frame to reduce GIF size\n",
    "            height, width = frame.shape[:2]\n",
    "            scaling_factor = max_width / float(width)\n",
    "            if width > max_width:  # Only resize if the image is wider than the max width\n",
    "                new_dim = (max_width, int(height * scaling_factor))\n",
    "                frame = cv2.resize(frame, new_dim, interpolation=cv2.INTER_AREA)\n",
    "            \n",
    "            frame_path = os.path.join(output_folder, f\"frame_{current_frame}.png\")\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            frames.append(frame_path)\n",
    "            print(f\"Extracted frame {current_frame}\")\n",
    "        \n",
    "        current_frame += 1\n",
    "    \n",
    "    # Close video file\n",
    "    cap.release()\n",
    "\n",
    "    # Create GIF\n",
    "    if frames:\n",
    "        with imageio.get_writer(os.path.join(output_folder, gif_name), mode='I', fps=fps) as writer:\n",
    "            for filename in frames:\n",
    "                image = imageio.imread(filename)\n",
    "                writer.append_data(image)\n",
    "        print(f\"GIF created at {os.path.join(output_folder, gif_name)}\")\n",
    "    else:\n",
    "        print(\"No frames extracted, GIF not created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_velocity(node_loc, window_size=25, polynomial_order=3):\n",
    "    \"\"\"\n",
    "    Calculate the velocity of tracked nodes from pose data.\n",
    "    \n",
    "    The function utilizes the Savitzky-Golay filter to smooth the data and compute the velocity.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    node_loc : numpy.ndarray\n",
    "        The location of nodes, represented as an array of shape [frames, 2]. \n",
    "        Each row represents x and y coordinates for a particular frame.\n",
    "        \n",
    "    window_size : int, optional\n",
    "        The size of the window used for the Savitzky-Golay filter. \n",
    "        Represents the number of consecutive data points used when smoothing the data.\n",
    "        Default is 25.\n",
    "        \n",
    "    polynomial_order : int, optional\n",
    "        The order of the polynomial fit to the data within the Savitzky-Golay filter window.\n",
    "        Default is 3.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        The velocity for each frame, calculated from the smoothed x and y coordinates.\n",
    "    \n",
    "    \"\"\"\n",
    "    node_loc_vel = np.zeros_like(node_loc)\n",
    "    \n",
    "    # For each coordinate (x and y), smooth the data and calculate the derivative (velocity)\n",
    "    for c in range(node_loc.shape[-1]):\n",
    "        node_loc_vel[:, c] = savgol_filter(node_loc[:, c], window_size, polynomial_order, deriv=1)\n",
    "    \n",
    "    # Calculate the magnitude of the velocity vectors for each frame\n",
    "    node_vel = np.linalg.norm(node_loc_vel, axis=1)\n",
    "\n",
    "    return node_vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_speed_from_distances(distances_array, window_size=25, polynomial_order=3):\n",
    "    \"\"\"\n",
    "    Compute the speed of an object moving along a path defined by distances covered over time. \n",
    "    The speed is calculated by smoothing the distances using the Savitzky-Golay filter to find \n",
    "    the rate of change of distance with respect to time (derivative), which represents the speed.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    distances_array : numpy.ndarray\n",
    "        An array containing distances covered over consecutive frames or time intervals. \n",
    "        Each value should represent the distance moved from the previous frame or time interval.\n",
    "        \n",
    "    window_size : int, optional\n",
    "        The length of the filter window, i.e., the number of coefficients. `window_size` must be a positive odd number.\n",
    "        Default is 25.\n",
    "        \n",
    "    polynomial_order : int, optional\n",
    "        The order of the polynomial used to fit the samples. `polynomial_order` must be less than `window_size`.\n",
    "        Default is 3.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        An array of the smoothed rate of change of distances, representing the speed for each frame or time interval.\n",
    "\n",
    "    Notes:\n",
    "    -----\n",
    "    - The function assumes that the input distances are sequential and represent uniform time intervals.\n",
    "    - The rate of change (speed) is computed using the first derivative with respect to the distance data.\n",
    "    \"\"\"\n",
    "    # Validate input\n",
    "    if polynomial_order >= window_size:\n",
    "        raise ValueError(\"polynomial_order must be less than window_size\")\n",
    "    \n",
    "    # Calculate the rate of change of the distance to get speed, using Savitzky-Golay filter\n",
    "    speed = savgol_filter(distances_array, window_size, polynomial_order, deriv=1)\n",
    "\n",
    "    return speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_speed_from_distances(distances, dt):\n",
    "#     \"\"\"\n",
    "#     Calculate the speed from a numpy array of distances measured at regular time intervals.\n",
    "\n",
    "#     Parameters:\n",
    "#         distances (np.array): 1D Numpy array where each element represents a distance measured at a specific time.\n",
    "#         dt (float): Time interval between consecutive distance measurements.\n",
    "\n",
    "#     Returns:\n",
    "#         np.array: Array of speeds calculated as the change in distance divided by the time interval.\n",
    "#     \"\"\"\n",
    "#     # Calculate the change in distance\n",
    "#     delta_distances = np.diff(distances, n=dt)\n",
    "\n",
    "#     # Calculate speeds as change in distance divided by change in time\n",
    "#     speeds = delta_distances / dt\n",
    "\n",
    "#     # Pad the speed array at the beginning with zero to maintain the same length\n",
    "#     speeds = np.concatenate([np.array([speeds[0]]), speeds])\n",
    "\n",
    "#     return speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rolling_average(arr, window_size):\n",
    "    \"\"\"\n",
    "    Computes the rolling average using a specified window size.\n",
    "    \n",
    "    Parameters:\n",
    "        arr (numpy.array): The input array to compute the rolling average for.\n",
    "        window_size (int): The size of the rolling window.\n",
    "\n",
    "    Returns:\n",
    "        numpy.array: The rolling average of the input array.\n",
    "    \"\"\"\n",
    "    if window_size < 1:\n",
    "       raise ValueError(\"Window size must be at least 1.\")\n",
    "    \n",
    "    # Create a uniform window of given window size\n",
    "    window = np.ones(window_size) / window_size\n",
    "\n",
    "    # Use numpy's convolve function to compute the rolling average\n",
    "    return np.convolve(arr, window, mode='valid')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chunked_average(arr, chunk_size):\n",
    "    \"\"\"\n",
    "    Computes the average for non-overlapping chunks of the input array.\n",
    "    \n",
    "    Parameters:\n",
    "        arr (numpy.array): The input array.\n",
    "        chunk_size (int): The size of each chunk.\n",
    "\n",
    "    Returns:\n",
    "        numpy.array: The averages of the non-overlapping chunks.\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of chunks\n",
    "    num_chunks = len(arr) // chunk_size\n",
    "    \n",
    "    # Reshape the array into a 2D array of shape (num_chunks, chunk_size)\n",
    "    reshaped_arr = arr[:num_chunks * chunk_size].reshape(num_chunks, chunk_size)\n",
    "    \n",
    "    # Compute the mean along the second axis (i.e., for each chunk)\n",
    "    return reshaped_arr.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sliding_window_average(arr, window_size, step=1):\n",
    "    \"\"\"\n",
    "    Apply a sliding window to a 1D numpy array, returning the average of windows of a specified size.\n",
    "\n",
    "    :param arr: Input 1D numpy array.\n",
    "    :param window_size: Size of the window.\n",
    "    :param step: The step size or number of elements to slide the window by. Default is 1.\n",
    "    :return: A 1D numpy array where each element is the average of a window from the input.\n",
    "    \"\"\"\n",
    "    # Number of windows\n",
    "    num_windows = ((arr.size - window_size) // step) + 1\n",
    "    \n",
    "    # Output array for averages\n",
    "    averages = np.zeros(num_windows)\n",
    "    \n",
    "    for i in range(num_windows):\n",
    "        # Calculate the start and end index for the window\n",
    "        start = i * step\n",
    "        end = start + window_size\n",
    "        # Calculate the average of the window\n",
    "        averages[i] = np.mean(arr[start:end])\n",
    "\n",
    "    return averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_all_window_indices(original_index, window_size, step, array_length):\n",
    "    \"\"\"\n",
    "    Calculate all the start and stop indices for sliding windows based on an original start index.\n",
    "\n",
    "    :param original_index: The original index from which the first window should start.\n",
    "    :param window_size: The size of each sliding window.\n",
    "    :param step: The step size or number of elements to slide the window by.\n",
    "    :param array_length: The total number of elements in the array.\n",
    "    :return: A list of tuples, each containing the start and stop indices for a sliding window.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the list to hold the start and stop indices for all windows\n",
    "    windows = []\n",
    "\n",
    "    # Initialize the current start index with the original index\n",
    "    current_start_index = original_index\n",
    "\n",
    "    # Loop through the array until the end is reached\n",
    "    while current_start_index + window_size <= original_index + array_length:\n",
    "        # Calculate the stop index based on the window size\n",
    "        stop_index = current_start_index + window_size\n",
    "\n",
    "        # Add the start and stop indices to the list\n",
    "        windows.append((current_start_index, stop_index))\n",
    "\n",
    "        # Update the current start index by adding the step size\n",
    "        current_start_index += step\n",
    "\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(ax, ay, bx, by, cx, cy):\n",
    "    \"\"\"\n",
    "    Calculate the smallest angle between the vectors BA and BC with all points given in Cartesian coordinates.\n",
    "\n",
    "    Parameters:\n",
    "        ax, ay (float): Coordinates of point A.\n",
    "        bx, by (float): Coordinates of point B, the vertex of the angle.\n",
    "        cx, cy (float): Coordinates of point C.\n",
    "\n",
    "    Returns:\n",
    "        float: The smallest angle between vectors BA and BC, in radians, within the range [0, pi].\n",
    "    \"\"\"\n",
    "    # Calculate the angles of vectors BA and BC relative to the positive x-axis\n",
    "    ang_ba = np.arctan2(ay - by, ax - bx)\n",
    "    ang_bc = np.arctan2(cy - by, cx - bx)\n",
    "\n",
    "    # Compute the difference of angles\n",
    "    ang = ang_bc - ang_ba\n",
    "\n",
    "    # Normalize the angle to the range [0, 2*pi)\n",
    "    ang = (ang + 2 * np.pi) % (2 * np.pi)\n",
    "\n",
    "    # Ensure the angle is within [0, pi]\n",
    "    if ang > np.pi:\n",
    "        ang = 2 * np.pi - ang\n",
    "\n",
    "    return ang\n",
    "\n",
    "# Example usage:\n",
    "ax, ay = 0, 1  # Coordinates for point A\n",
    "bx, by = 0, 0  # Coordinates for point B (origin)\n",
    "cx, cy = -0.5, 0.5  # Coordinates for point C\n",
    "\n",
    "angle = calculate_angle(ax, ay, bx, by, cx, cy)\n",
    "print(\"Angle in radians:\", angle)\n",
    "print(\"Angle in degrees:\", np.degrees(angle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_time_series_angles(A, B, C):\n",
    "    \"\"\"\n",
    "    Calculate the smallest angle between vectors BA and BC for arrays of 2D points over time.\n",
    "\n",
    "    Parameters:\n",
    "        A, B, C (np.array): Each is a 2D numpy array of shape (T, 2) where T is the number of time steps.\n",
    "                            Each array holds the x and y coordinates of points A, B, and C over time.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Array of smallest angles between vectors BA and BC, in radians, within the range [0, pi].\n",
    "    \"\"\"\n",
    "    # Extract x and y coordinates\n",
    "    ax, ay = A[:, 0], A[:, 1]\n",
    "    bx, by = B[:, 0], B[:, 1]\n",
    "    cx, cy = C[:, 0], C[:, 1]\n",
    "    \n",
    "    # Calculate the angles of vectors BA and BC relative to the positive x-axis\n",
    "    ang_ba = np.arctan2(ay - by, ax - bx)\n",
    "    ang_bc = np.arctan2(cy - by, cx - bx)\n",
    "    \n",
    "    # Compute the difference of angles\n",
    "    ang = ang_bc - ang_ba\n",
    "    \n",
    "    # Normalize the angle to the range [0, 2*pi)\n",
    "    ang = (ang + 2 * np.pi) % (2 * np.pi)\n",
    "    \n",
    "    # Ensure the angle is within [0, pi]\n",
    "    ang[ang > np.pi] = 2 * np.pi - ang[ang > np.pi]\n",
    "    \n",
    "    return ang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating and stacking arrays from all columns\n",
    "def concat_arrays(row):\n",
    "    return np.hstack(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(a, n=3):\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d290bac2c17940bfbc0f9296beaf70e5",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Inputs & Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e528ce19c608425292151930d380f49f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Explanation of each input and where it comes from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "6cf83a5811054461a718a71673d09aab",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 373,
    "execution_start": 1691424003628,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inputs and Required data loading\n",
    "# input varaible names are in all caps snake case\n",
    "# Whenever an input changes or is used for processing \n",
    "# the vairables are all lower in snake case\n",
    "THORAX_INDEX = 1\n",
    "\n",
    "# LFP_SPECTRAL_DF = pd.read_pickle(\"./proc/rce_pilot_2_03_spectral_bands.pkl\")\n",
    "# LFP_SPECTRAL_DF[\"video_name\"] = LFP_SPECTRAL_DF[\"video_name\"].apply(lambda x: x.strip(\".videoTimeStamps.cameraHWSync\"))\n",
    "\n",
    "# SLEAP_DIR = os.path.join(git_root, \"proc/sleap\") \n",
    "# SLEAP_DIR = \"/scratch/back_up/reward_competition_extention/final_proc/id_corrected\"\n",
    "SLEAP_DIR = \"./data\"\n",
    "\n",
    "OUTPUT_DIR = r\"./proc\" # where data is saved should always be shown in the inputs\n",
    "MED_PC_WIDTH = 29.5\n",
    "MED_PC_HEIGHT = 24\n",
    "FRAME_RATE = 22\n",
    "WINDOW_SIZE = 25\n",
    "DISTANCE_THRESHOLD = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_start_stop_files = [\"./data/rce_pilot_3_long_comp_per_subject_start_stop_video_frame.xlsx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_files = [\"./data/rce_pilot_3_long_comp_per_video_trial_labels.xlsx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all_start_stop_files = [\"./data/rce_pilot_3_long_comp_per_subject_start_stop_video_frame.xlsx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all_trials_files = [\"./data/rce_pilot_3_long_comp_per_video_trial_labels.xlsx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_start_stop_df = []\n",
    "\n",
    "for file_path in all_start_stop_files:\n",
    "    exploded_columns = pd.read_excel(file_path)\n",
    "    list_of_start_stop_df.append(exploded_columns)\n",
    "\n",
    "START_STOP_FRAME_DF = pd.concat(list_of_start_stop_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e3ee4891d43a4ac287413afc552ca289",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9ccbf6cc70fd4d379fa29317f733771f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe each output that the notebook creates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fc8e8920a6944918a15fac575cdf6e78",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- Is it a plot or is it data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1e639d4776a84aa9ac8ded2e14fa57db",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- How valuable is the output and why is it valuable or useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inputs and Required data loading\n",
    "# input varaible names are in all caps snake case\n",
    "# Whenever an input changes or is used for processing \n",
    "# the vairables are all lower in snake case\n",
    "OUTPUT_DIR = r\"./proc/\" # where data is saved should always be shown in the inputs\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "OUTPUT_PREFIX = \"rce_pilot_3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FULL_LFP_TRACES_PKL = \"{}_04_spectral_and_sleap.pkl\".format(OUTPUT_PREFIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8999d19b6b7d4d63bc90f0b0bd9ab085",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9b36cdf08567463082b005cb0dec684b",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe what is done to the data here and how inputs are manipulated to generate outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exploded_columns = pd.read_pickle(\"./proc/exploded_columns.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exploded_columns.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exploded_columns[\"within_trial_index\"] = exploded_columns[\"frame_index\"] - exploded_columns[\"tone_start_frame\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exploded_columns = exploded_columns.drop_duplicates(subset=[\"frame_index\", \"video_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exploded_columns[\"within_trial_frame_index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    exploded_columns[\"standard_embedding_x\"],\n",
    "    exploded_columns[\"standard_embedding_y\"],\n",
    "    s=0.1)\n",
    "plt.gca().set_aspect('equal', 'datalim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nose_to_reward_port_sum_df = pd.DataFrame(exploded_columns.groupby([\"kmeans_cluster\"])[\"nose_to_reward_port_sum\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nose_to_reward_port_sum_df[\"rank_nose_to_reward_port_sum\"] = nose_to_reward_port_sum_df[\"nose_to_reward_port_sum\"].rank().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nose_to_reward_port_sum_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_to_competitiveness = {\"0\": \"no_comp\", \"1\": \"competitive\", \"2\": \"no_comp\", \"3\": \"competitive\", \"4\": \"no_comp\", \"5\": \"competitive\", \"6\": \"no_comp\", \"7\": \"no_comp\"}\n",
    "cluster_to_comp_id = {\"0\": \"no_comp_5\", \"1\": \"competitive_2\", \"2\": \"no_comp_8\", \"3\": \"competitive_4\", \"4\": \"no_comp_7\", \"5\": \"competitive_1\", \"6\": \"no_comp_6\", \"7\": \"competitive_3\"}\n",
    "# comp_id = {\"no_comp_8\", \"competitive_3\", \"competitive_1\", \"no_comp_6\", \"competitive_2\", \"no_comp_7\", \"no_comp_5\", \"no_comp_4\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster notes\n",
    "\n",
    "0: Not, lower half but usually not looking at the port\n",
    "1: Highly Competitive, both near port and trying to actively get to port\n",
    "2: Not, both upper and lower half but usually not looking at the port\n",
    "3: Highly Competitive, both near port and trying to actively get to port\n",
    "4: Competitive, both near port\n",
    "5: Not, looking towards near upper half\n",
    "6: Competitive, both near port probably moving related\n",
    "7: Not, looking away near upper half"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competitive colors\n",
    "Original color: 43246A\n",
    "Lighter to darker \n",
    "\n",
    "#7b6697\n",
    "#43246A\n",
    "#2f194a\n",
    "#1b0e2a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not colors\n",
    "Original color: 768800\n",
    "Lighter to darker (30 or 60%)\n",
    "\n",
    "\n",
    "#9fac4d\n",
    "#768800\n",
    "#535f00\n",
    "#2f3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_to_competitiveness = {\"0\": \"no_comp\", \"1\": \"competitive\", \"2\": \"no_comp\", \"3\": \"competitive\", \"4\": \"competitive\", \"5\": \"no_comp\", \"6\": \"competitive\", \"7\": \"no_comp\"}\n",
    "# cluster_to_comp_id = {\"0\": \"no_comp_5\", \"1\": \"competitive_2\", \"2\": \"no_comp_6\", \"3\": \"competitive_1\", \"4\": \"competitive_3\", \"5\": \"no_comp_7\", \"6\": \"competitive_4\", \"7\": \"no_comp_8\"}\n",
    "# # comp_id = {\"no_comp_8\", \"competitive_3\", \"competitive_1\", \"no_comp_6\", \"competitive_2\", \"no_comp_7\", \"no_comp_5\", \"no_comp_4\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_id_to_color = {'competitive_1': \"#1b0e2a\",\n",
    " 'competitive_2': \"#2f194a\",\n",
    " 'competitive_3': \"#43246A\",\n",
    " 'competitive_4': \"#7b6697\",\n",
    " 'no_comp_5': \"#2f3600\",\n",
    " 'no_comp_6': \"#535f00\",\n",
    " 'no_comp_7': \"#768800\",\n",
    " 'no_comp_8': \"#9fac4d\"}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_columns[\"kmeans_cluster\"] = exploded_columns[\"kmeans_cluster\"].astype(str)\n",
    "exploded_columns[\"competitiveness\"] = exploded_columns[\"kmeans_cluster\"].map(cluster_to_competitiveness)\n",
    "exploded_columns[\"comp_id\"] = exploded_columns[\"kmeans_cluster\"].map(cluster_to_comp_id)\n",
    "exploded_columns[\"color\"] = exploded_columns[\"comp_id\"].map(comp_id_to_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_columns[\"comp_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "# plt.figure()\n",
    "\n",
    "for comp_id in sorted(exploded_columns[\"comp_id\"].unique()):\n",
    "    current_df = exploded_columns[exploded_columns[\"comp_id\"] == comp_id].copy()\n",
    "\n",
    "    plt.scatter(\n",
    "        current_df[\"standard_embedding_x\"],\n",
    "        current_df[\"standard_embedding_y\"],\n",
    "        s=0.1,\n",
    "        label=\" \".join(comp_id.split(\"_\")),\n",
    "        c=comp_id_to_color[comp_id])\n",
    "\n",
    "\n",
    "# lgnd = plt.legend(fontsize=50)\n",
    "# for handle in lgnd.legend_handles:\n",
    "#     handle.set_sizes([50])\n",
    "\n",
    "plt.xlabel(\"UMAP 1\", fontsize=60)\n",
    "plt.ylabel(\"UMAP 2\", fontsize=60)\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title(\"K-means behavioral clustering\", fontsize=60)\n",
    "ax.tick_params(axis='both', which='major', labelsize=50)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=50)\n",
    "# Hide top and right borders\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Leave bottom and left spines\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "\n",
    "ax.get_xaxis().set_ticks([])\n",
    "ax.get_yaxis().set_ticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./proc/kmeans_cluster_ids.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "# plt.figure()\n",
    "\n",
    "for video_id in sorted(exploded_columns[\"video_id\"].unique()):\n",
    "    current_df = exploded_columns[exploded_columns[\"video_id\"] == video_id].copy()\n",
    "\n",
    "    plt.scatter(\n",
    "        current_df[\"standard_embedding_x\"],\n",
    "        current_df[\"standard_embedding_y\"],\n",
    "        s=0.1,\n",
    "        label=video_id)\n",
    "\n",
    "\n",
    "lgnd = plt.legend()\n",
    "for handle in lgnd.legend_handles:\n",
    "    handle.set_sizes([50])\n",
    "\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title(\"Video IDs\")\n",
    "plt.savefig(\"./proc/video_cluster_ids.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = cm.viridis  # Choose a colormap\n",
    "cmap = cm.Spectral  # Choose a colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgnd = plt.legend(fontsize=24)\n",
    "# for handle in lgnd.legend_handles:\n",
    "#     handle.set_sizes([50])\n",
    "\n",
    "plt.xlabel(\"UMAP 1\", fontsize=60)\n",
    "plt.ylabel(\"UMAP 2\", fontsize=60)\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title(\"K-means behavioral clustering\", fontsize=60)\n",
    "ax.tick_params(axis='both', which='major', labelsize=50)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=50)\n",
    "# Hide top and right borders\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Leave bottom and left spines\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "\n",
    "ax.get_xaxis().set_ticks([])\n",
    "ax.get_yaxis().set_ticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./proc/kmeans_cluster_ids.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_features_columns = [\"nose_to_reward_port_sum\", \"thorax_velocity_sum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_to_title = {\"nose_to_reward_port_sum\": \"Distances to Port\", \"thorax_velocity_sum\": \"Velocity\"}\n",
    "feat_to_legend = {\"nose_to_reward_port_sum\": \"Combined distances\", \"thorax_velocity_sum\": \"Combined velocity\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for featured in current_features_columns:\n",
    "    if featured == \"frame_index\":\n",
    "        continue\n",
    "    print(featured)\n",
    "\n",
    "    exploded_columns[\"zscored_{}\".format(featured)] = stats.zscore(exploded_columns[featured].values.astype(float))\n",
    "\n",
    "    filtered_exploded_columns = exploded_columns[np.abs(exploded_columns[\"zscored_{}\".format(featured)]) <= 2.5].copy()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "    norm = Normalize(vmin=np.min(filtered_exploded_columns[featured].astype(float)), vmax=np.max(filtered_exploded_columns[featured].astype(float)))  # Normalize to the data range\n",
    "    plt.scatter(\n",
    "        filtered_exploded_columns[\"standard_embedding_x\"],\n",
    "        filtered_exploded_columns[\"standard_embedding_y\"],\n",
    "        c=filtered_exploded_columns[featured].astype(float),\n",
    "        s=0.05, cmap = cmap, norm=norm)\n",
    "\n",
    "    # plt.title(feat_to_title[featured], fontsize=60)\n",
    "    cbar = plt.colorbar(orientation=\"vertical\", fraction=0.026, pad=0.04).ax.tick_params(labelsize=30) \n",
    "\n",
    "\n",
    "    # plt.xlabel(\"UMAP 1\", fontsize=60)\n",
    "    # plt.ylabel(\"UMAP 2\", fontsize=60)\n",
    "    plt.gca().set_aspect('equal', 'datalim')\n",
    "    ax.tick_params(axis='both', which='major', labelsize=50)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=50)\n",
    "    # Hide top and right borders\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    # Leave bottom and left spines\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "\n",
    "    ax.get_xaxis().set_ticks([])\n",
    "    ax.get_yaxis().set_ticks([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "    plt.savefig(\"./proc/{}_umap.png\".format(featured))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# The number to look for in 'group_number'\n",
    "number_to_count = 1\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for comp_id in sorted(exploded_columns[\"comp_id\"].unique()):\n",
    "    # Counting occurrences of 'number_to_count' in each 'index'\n",
    "    occurrences = exploded_columns[exploded_columns['comp_id'] == comp_id]['within_trial_index'].value_counts().sort_index()\n",
    "    plt.plot(occurrences.index[:599]/20, occurrences.values[:599], marker='', linestyle='-', label=comp_id, color=comp_id_to_color[comp_id], linewidth=4)\n",
    "\n",
    "plt.axvline(x=0, color=\"green\", label=\"tone start\", linewidth=4)\n",
    "plt.axvline(x=4, color=\"orange\", label=\"reward dispensed\", linewidth=4)\n",
    "plt.axvline(x=10, color=\"red\", label=\"tone stop\", linewidth=4)\n",
    "ax.tick_params(axis='both', which='major', labelsize=30)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=30)\n",
    "\n",
    "\n",
    "# plt.legend()\n",
    "# Plotting\n",
    "plt.title(f'Behavior cluster frequency in trials', fontsize=50)\n",
    "plt.xlabel('Time from trial start(seconds)', fontsize=35)\n",
    "plt.ylabel('Number of frames', fontsize=35)\n",
    "plt.xlim(-10, 20)\n",
    "# plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./proc/across_trial_comp.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.collections import PolyCollection\n",
    "\n",
    "data = [    (dt.datetime(2018, 7, 17, 0, 15), dt.datetime(2018, 7, 17, 0, 30), 'sleep'),\n",
    "            (dt.datetime(2018, 7, 17, 0, 30), dt.datetime(2018, 7, 17, 0, 45), 'eat'),\n",
    "            (dt.datetime(2018, 7, 17, 0, 45), dt.datetime(2018, 7, 17, 1, 0), 'work'),\n",
    "            (dt.datetime(2018, 7, 17, 1, 0), dt.datetime(2018, 7, 17, 1, 30), 'sleep'),\n",
    "            (dt.datetime(2018, 7, 17, 1, 15), dt.datetime(2018, 7, 17, 1, 30), 'eat'), \n",
    "            (dt.datetime(2018, 7, 17, 1, 30), dt.datetime(2018, 7, 17, 1, 45), 'work')\n",
    "        ]\n",
    "\n",
    "cats = {\"sleep\" : 1, \"eat\" : 2, \"work\" : 3}\n",
    "colormapping = {\"sleep\" : \"C0\", \"eat\" : \"C1\", \"work\" : \"C2\"}\n",
    "\n",
    "verts = []\n",
    "colors = []\n",
    "for d in data:\n",
    "    v =  [(mdates.date2num(d[0]), cats[d[2]]-.4),\n",
    "          (mdates.date2num(d[0]), cats[d[2]]+.4),\n",
    "          (mdates.date2num(d[1]), cats[d[2]]+.4),\n",
    "          (mdates.date2num(d[1]), cats[d[2]]-.4),\n",
    "          (mdates.date2num(d[0]), cats[d[2]]-.4)]\n",
    "    verts.append(v)\n",
    "    colors.append(colormapping[d[2]])\n",
    "\n",
    "bars = PolyCollection(verts, facecolors=colors)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.add_collection(bars)\n",
    "ax.autoscale()\n",
    "loc = mdates.MinuteLocator(byminute=[0,15,30,45])\n",
    "ax.xaxis.set_major_locator(loc)\n",
    "ax.xaxis.set_major_formatter(mdates.AutoDateFormatter(loc))\n",
    "\n",
    "ax.set_yticks([1,2,3])\n",
    "ax.set_yticklabels([\"sleep\", \"eat\", \"work\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for featured in current_features_columns:\n",
    "#     if featured == \"frame_index\":\n",
    "#         continue\n",
    "#     print(featured)\n",
    "#     fig, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "#     norm = Normalize(vmin=np.min(exploded_columns[featured].astype(float)), vmax=np.max(exploded_columns[featured].astype(float)))  # Normalize to the data range\n",
    "#     plt.scatter(\n",
    "#         exploded_columns[\"standard_embedding_x\"],\n",
    "#         exploded_columns[\"standard_embedding_y\"],\n",
    "#         c=exploded_columns[featured].astype(float),\n",
    "#         s=0.05, cmap = cmap, norm=norm)\n",
    "\n",
    "#     # plt.title(feat_to_title[featured], fontsize=60)\n",
    "#     cbar = plt.colorbar(orientation=\"vertical\", fraction=0.026, pad=0.04).ax.tick_params(labelsize=30) \n",
    "\n",
    "\n",
    "#     # plt.xlabel(\"UMAP 1\", fontsize=60)\n",
    "#     # plt.ylabel(\"UMAP 2\", fontsize=60)\n",
    "#     plt.gca().set_aspect('equal', 'datalim')\n",
    "#     ax.tick_params(axis='both', which='major', labelsize=50)\n",
    "#     ax.tick_params(axis='both', which='minor', labelsize=50)\n",
    "#     # Hide top and right borders\n",
    "#     ax.spines['top'].set_visible(False)\n",
    "#     ax.spines['right'].set_visible(False)\n",
    "\n",
    "#     # Leave bottom and left spines\n",
    "#     ax.spines['bottom'].set_visible(False)\n",
    "#     ax.spines['left'].set_visible(False)\n",
    "\n",
    "#     ax.get_xaxis().set_ticks([])\n",
    "#     ax.get_yaxis().set_ticks([])\n",
    "\n",
    "#     plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "#     plt.savefig(\"./proc/{}_umap.png\".format(featured))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping all the rows by video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(exploded_columns.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep_columns = [\n",
    " 'tone_start_frame',\n",
    " 'tone_start_timestamp',\n",
    " 'tone_start_to_stop_frame',\n",
    " 'tone_stop_frame',\n",
    " 'tone_stop_timestamp',\n",
    " 'tracked_subject',\n",
    " 'video_id',\n",
    " 'video_name',\n",
    " 'within_trial_frame_index',\n",
    " 'within_trial_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_exploded_columns = export_exploded_columns.dropna(subset=[\"condition \"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_exploded_columns = export_exploded_columns.sort_values(by=[\"video_name\", \"current_subject\", \"frame_index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_exploded_columns[\"tone_start_frame\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleap_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns to be transformed into numpy arrays\n",
    "array_columns = ['frame_index', 'tone_start_frame',\n",
    "       'tone_stop_frame', 'condition ',\n",
    "       'competition_closeness', 'notes', '10s_before_tone_frame',\n",
    "       '10s_after_tone_frame', 'subject_thorax_to_agent_thorax',\n",
    "       'nose_to_reward_port_sum', 'nose_to_reward_port_diff',\n",
    "       'thorax_velocity_sum', 'thorax_velocity_diff',\n",
    "       'to_reward_port_angle_sum', 'to_reward_port_angle_diff',\n",
    "       'subject_nose_to_reward_port', 'subject_thorax_velocity',\n",
    "       'subject_to_reward_port_angle', 'agent_nose_to_reward_port',\n",
    "       'agent_thorax_velocity', 'agent_to_reward_port_angle',\n",
    "       'closebool_subject_nose_to_reward_port',\n",
    "       'closebool_agent_nose_to_reward_port',\n",
    "       'movingbool_subject_thorax_velocity',\n",
    "       'movingbool_agent_thorax_velocity', 'manual_cluster_id',\n",
    "       'standard_embedding_x', 'standard_embedding_y',\n",
    "       'kmeans_cluster', 'manual_cluster_id',] + sleap_columns\n",
    "#'clusterable_embedding_x', 'clusterable_embedding_y', \n",
    "# Define columns to take the first value\n",
    "# first_value_columns = ['session_dir', 'experiment', 'sleap_name',\n",
    "#        'video_name', 'current_subject', 'video_id']\n",
    "\n",
    "first_value_columns = ['session_dir', 'experiment', 'sleap_name',\n",
    "      'video_id', \"agent\"]\n",
    "\n",
    "# Define aggregation dictionary\n",
    "# agg_dict = {col: lambda x: np.array(x) for col in array_columns}\n",
    "agg_dict = {col: list for col in array_columns}\n",
    "\n",
    "agg_dict.update({col: 'first' for col in first_value_columns})\n",
    "\n",
    "# Apply groupby and aggregation\n",
    "grouped_exploded_columns = export_exploded_columns.groupby([\"video_name\", \"current_subject\"]).agg(agg_dict).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_exploded_columns[\"frame_index\"] = grouped_exploded_columns[\"frame_index\"].apply(lambda x: np.array(x).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in array_columns:\n",
    "    grouped_exploded_columns[col] = grouped_exploded_columns[col].apply(lambda x: np.array(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_exploded_columns[\"video_name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_exploded_columns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_exploded_columns.to_pickle(\"./proc/grouped_exploded_columns.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "cf8fe3695d074ee7887fdf6459cbf5ce",
  "kernelspec": {
   "display_name": "mountainsort_0_5_6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
