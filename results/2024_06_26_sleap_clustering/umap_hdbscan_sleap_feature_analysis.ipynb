{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c3a02adc9e884466bc8c79db549cc3d2",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 17,
      "type": "marks"
     }
    ]
   },
   "source": [
    "# SLEAP Distance Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4546bee655b14a5dbf393161f1228e60",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Brief 1-2 sentence description of notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling it a second time may prevent some graphics errors\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import git\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "03b495cefa6a4798a44c7f2e4c6a3ea7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 21,
    "execution_start": 1691424003626,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports of all used packages and libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "# import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import savgol_filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.cluster as cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "git_repo = git.Repo(\".\", search_parent_directories=True)\n",
    "git_root = git_repo.git.rev_parse(\"--show-toplevel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "git_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.join(git_root, 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import utilities.helper\n",
    "import sleap.process_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import imageio\n",
    "import hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sns.set('notebook', 'ticks', font_scale=1.2)\n",
    "mpl.rcParams['figure.figsize'] = [15,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angles_from_arrays(A, B, C, D):\n",
    "    \"\"\"\n",
    "    Calculate the angles between vectors AB and CD for arrays of 2D points.\n",
    "\n",
    "    Parameters:\n",
    "    - A, B, C, D: Each is a 2D numpy array where each row represents a point in 2D space.\n",
    "                  A and B represent points defining the first vector, AB, and C and D represent points defining the second vector, CD.\n",
    "\n",
    "    Returns:\n",
    "    - A numpy array of angles in degrees between the vectors AB and CD for each set of points.\n",
    "    \"\"\"\n",
    "    # Ensure input arrays are numpy arrays\n",
    "    A, B, C, D = map(np.array, [A, B, C, D])\n",
    "\n",
    "    # Calculate vectors AB and CD\n",
    "    AB = B - A\n",
    "    CD = D - C\n",
    "\n",
    "    # Calculate dot products and magnitudes for each pair of vectors\n",
    "    dot_products = np.einsum('ij,ij->i', AB, CD)\n",
    "    norms_AB = np.linalg.norm(AB, axis=1)\n",
    "    norms_CD = np.linalg.norm(CD, axis=1)\n",
    "\n",
    "    # Calculate cosine of the angle using the dot product and magnitudes\n",
    "    cos_angles = dot_products / (norms_AB * norms_CD)\n",
    "    \n",
    "    # Clip values to prevent domain errors due to numerical issues\n",
    "    cos_angles = np.clip(cos_angles, -1.0, 1.0)\n",
    "\n",
    "    # Calculate angles in radians and then convert to degrees\n",
    "    angles_radians = np.arccos(cos_angles)\n",
    "    angles_degrees = np.degrees(angles_radians)\n",
    "\n",
    "    return angles_degrees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames_and_make_gif(video_path, frame_numbers, output_folder, gif_name=\"output.gif\", fps=10, max_width=640):\n",
    "    \"\"\"\n",
    "    Extracts frames from a video at specific frame numbers, resizes them, and creates a GIF from those frames.\n",
    "\n",
    "    Parameters:\n",
    "        video_path (str): Path to the video file.\n",
    "        frame_numbers (list): List of frame numbers to extract.\n",
    "        output_folder (str): Directory to save the frames and GIF.\n",
    "        gif_name (str): Filename for the GIF.\n",
    "        fps (int): Frames per second for the GIF.\n",
    "        max_width (int): Maximum width of the frames in the GIF. Height is adjusted proportionally.\n",
    "    \"\"\"\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Initialize video capture\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    # Prepare to extract frames\n",
    "    frames = []\n",
    "    frame_ids = set(frame_numbers)  # Convert list to set for faster lookup\n",
    "    current_frame = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        if current_frame in frame_ids:\n",
    "            # Resize frame to reduce GIF size\n",
    "            height, width = frame.shape[:2]\n",
    "            scaling_factor = max_width / float(width)\n",
    "            if width > max_width:  # Only resize if the image is wider than the max width\n",
    "                new_dim = (max_width, int(height * scaling_factor))\n",
    "                frame = cv2.resize(frame, new_dim, interpolation=cv2.INTER_AREA)\n",
    "            \n",
    "            frame_path = os.path.join(output_folder, f\"frame_{current_frame}.png\")\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            frames.append(frame_path)\n",
    "            print(f\"Extracted frame {current_frame}\")\n",
    "        \n",
    "        current_frame += 1\n",
    "    \n",
    "    # Close video file\n",
    "    cap.release()\n",
    "\n",
    "    # Create GIF\n",
    "    if frames:\n",
    "        with imageio.get_writer(os.path.join(output_folder, gif_name), mode='I', fps=fps) as writer:\n",
    "            for filename in frames:\n",
    "                image = imageio.imread(filename)\n",
    "                writer.append_data(image)\n",
    "        print(f\"GIF created at {os.path.join(output_folder, gif_name)}\")\n",
    "    else:\n",
    "        print(\"No frames extracted, GIF not created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_velocity(node_loc, window_size=25, polynomial_order=3):\n",
    "    \"\"\"\n",
    "    Calculate the velocity of tracked nodes from pose data.\n",
    "    \n",
    "    The function utilizes the Savitzky-Golay filter to smooth the data and compute the velocity.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    node_loc : numpy.ndarray\n",
    "        The location of nodes, represented as an array of shape [frames, 2]. \n",
    "        Each row represents x and y coordinates for a particular frame.\n",
    "        \n",
    "    window_size : int, optional\n",
    "        The size of the window used for the Savitzky-Golay filter. \n",
    "        Represents the number of consecutive data points used when smoothing the data.\n",
    "        Default is 25.\n",
    "        \n",
    "    polynomial_order : int, optional\n",
    "        The order of the polynomial fit to the data within the Savitzky-Golay filter window.\n",
    "        Default is 3.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        The velocity for each frame, calculated from the smoothed x and y coordinates.\n",
    "    \n",
    "    \"\"\"\n",
    "    node_loc_vel = np.zeros_like(node_loc)\n",
    "    \n",
    "    # For each coordinate (x and y), smooth the data and calculate the derivative (velocity)\n",
    "    for c in range(node_loc.shape[-1]):\n",
    "        node_loc_vel[:, c] = savgol_filter(node_loc[:, c], window_size, polynomial_order, deriv=1)\n",
    "    \n",
    "    # Calculate the magnitude of the velocity vectors for each frame\n",
    "    node_vel = np.linalg.norm(node_loc_vel, axis=1)\n",
    "\n",
    "    return node_vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rolling_average(arr, window_size):\n",
    "    \"\"\"\n",
    "    Computes the rolling average using a specified window size.\n",
    "    \n",
    "    Parameters:\n",
    "        arr (numpy.array): The input array to compute the rolling average for.\n",
    "        window_size (int): The size of the rolling window.\n",
    "\n",
    "    Returns:\n",
    "        numpy.array: The rolling average of the input array.\n",
    "    \"\"\"\n",
    "    if window_size < 1:\n",
    "       raise ValueError(\"Window size must be at least 1.\")\n",
    "    \n",
    "    # Create a uniform window of given window size\n",
    "    window = np.ones(window_size) / window_size\n",
    "\n",
    "    # Use numpy's convolve function to compute the rolling average\n",
    "    return np.convolve(arr, window, mode='valid')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chunked_average(arr, chunk_size):\n",
    "    \"\"\"\n",
    "    Computes the average for non-overlapping chunks of the input array.\n",
    "    \n",
    "    Parameters:\n",
    "        arr (numpy.array): The input array.\n",
    "        chunk_size (int): The size of each chunk.\n",
    "\n",
    "    Returns:\n",
    "        numpy.array: The averages of the non-overlapping chunks.\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of chunks\n",
    "    num_chunks = len(arr) // chunk_size\n",
    "    \n",
    "    # Reshape the array into a 2D array of shape (num_chunks, chunk_size)\n",
    "    reshaped_arr = arr[:num_chunks * chunk_size].reshape(num_chunks, chunk_size)\n",
    "    \n",
    "    # Compute the mean along the second axis (i.e., for each chunk)\n",
    "    return reshaped_arr.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sliding_window_average(arr, window_size, step=1):\n",
    "    \"\"\"\n",
    "    Apply a sliding window to a 1D numpy array, returning the average of windows of a specified size.\n",
    "\n",
    "    :param arr: Input 1D numpy array.\n",
    "    :param window_size: Size of the window.\n",
    "    :param step: The step size or number of elements to slide the window by. Default is 1.\n",
    "    :return: A 1D numpy array where each element is the average of a window from the input.\n",
    "    \"\"\"\n",
    "    # Number of windows\n",
    "    num_windows = ((arr.size - window_size) // step) + 1\n",
    "    \n",
    "    # Output array for averages\n",
    "    averages = np.zeros(num_windows)\n",
    "    \n",
    "    for i in range(num_windows):\n",
    "        # Calculate the start and end index for the window\n",
    "        start = i * step\n",
    "        end = start + window_size\n",
    "        # Calculate the average of the window\n",
    "        averages[i] = np.mean(arr[start:end])\n",
    "\n",
    "    return averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_all_window_indices(original_index, window_size, step, array_length):\n",
    "    \"\"\"\n",
    "    Calculate all the start and stop indices for sliding windows based on an original start index.\n",
    "\n",
    "    :param original_index: The original index from which the first window should start.\n",
    "    :param window_size: The size of each sliding window.\n",
    "    :param step: The step size or number of elements to slide the window by.\n",
    "    :param array_length: The total number of elements in the array.\n",
    "    :return: A list of tuples, each containing the start and stop indices for a sliding window.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the list to hold the start and stop indices for all windows\n",
    "    windows = []\n",
    "\n",
    "    # Initialize the current start index with the original index\n",
    "    current_start_index = original_index\n",
    "\n",
    "    # Loop through the array until the end is reached\n",
    "    while current_start_index + window_size <= original_index + array_length:\n",
    "        # Calculate the stop index based on the window size\n",
    "        stop_index = current_start_index + window_size\n",
    "\n",
    "        # Add the start and stop indices to the list\n",
    "        windows.append((current_start_index, stop_index))\n",
    "\n",
    "        # Update the current start index by adding the step size\n",
    "        current_start_index += step\n",
    "\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(ax, ay, bx, by, cx, cy):\n",
    "    \"\"\"\n",
    "    Calculate the smallest angle between the vectors BA and BC with all points given in Cartesian coordinates.\n",
    "\n",
    "    Parameters:\n",
    "        ax, ay (float): Coordinates of point A.\n",
    "        bx, by (float): Coordinates of point B, the vertex of the angle.\n",
    "        cx, cy (float): Coordinates of point C.\n",
    "\n",
    "    Returns:\n",
    "        float: The smallest angle between vectors BA and BC, in radians, within the range [0, pi].\n",
    "    \"\"\"\n",
    "    # Calculate the angles of vectors BA and BC relative to the positive x-axis\n",
    "    ang_ba = np.arctan2(ay - by, ax - bx)\n",
    "    ang_bc = np.arctan2(cy - by, cx - bx)\n",
    "\n",
    "    # Compute the difference of angles\n",
    "    ang = ang_bc - ang_ba\n",
    "\n",
    "    # Normalize the angle to the range [0, 2*pi)\n",
    "    ang = (ang + 2 * np.pi) % (2 * np.pi)\n",
    "\n",
    "    # Ensure the angle is within [0, pi]\n",
    "    if ang > np.pi:\n",
    "        ang = 2 * np.pi - ang\n",
    "\n",
    "    return ang\n",
    "\n",
    "# Example usage:\n",
    "ax, ay = 0, 1  # Coordinates for point A\n",
    "bx, by = 0, 0  # Coordinates for point B (origin)\n",
    "cx, cy = -0.5, 0.5  # Coordinates for point C\n",
    "\n",
    "angle = calculate_angle(ax, ay, bx, by, cx, cy)\n",
    "print(\"Angle in radians:\", angle)\n",
    "print(\"Angle in degrees:\", np.degrees(angle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_time_series_angles(A, B, C):\n",
    "    \"\"\"\n",
    "    Calculate the smallest angle between vectors BA and BC for arrays of 2D points over time.\n",
    "\n",
    "    Parameters:\n",
    "        A, B, C (np.array): Each is a 2D numpy array of shape (T, 2) where T is the number of time steps.\n",
    "                            Each array holds the x and y coordinates of points A, B, and C over time.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Array of smallest angles between vectors BA and BC, in radians, within the range [0, pi].\n",
    "    \"\"\"\n",
    "    # Extract x and y coordinates\n",
    "    ax, ay = A[:, 0], A[:, 1]\n",
    "    bx, by = B[:, 0], B[:, 1]\n",
    "    cx, cy = C[:, 0], C[:, 1]\n",
    "    \n",
    "    # Calculate the angles of vectors BA and BC relative to the positive x-axis\n",
    "    ang_ba = np.arctan2(ay - by, ax - bx)\n",
    "    ang_bc = np.arctan2(cy - by, cx - bx)\n",
    "    \n",
    "    # Compute the difference of angles\n",
    "    ang = ang_bc - ang_ba\n",
    "    \n",
    "    # Normalize the angle to the range [0, 2*pi)\n",
    "    ang = (ang + 2 * np.pi) % (2 * np.pi)\n",
    "    \n",
    "    # Ensure the angle is within [0, pi]\n",
    "    ang[ang > np.pi] = 2 * np.pi - ang[ang > np.pi]\n",
    "    \n",
    "    return ang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating and stacking arrays from all columns\n",
    "def concat_arrays(row):\n",
    "    return np.hstack(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_speed_from_distances(distances, dt):\n",
    "    \"\"\"\n",
    "    Calculate the speed from a numpy array of distances measured at regular time intervals.\n",
    "\n",
    "    Parameters:\n",
    "        distances (np.array): 1D Numpy array where each element represents a distance measured at a specific time.\n",
    "        dt (float): Time interval between consecutive distance measurements.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Array of speeds calculated as the change in distance divided by the time interval.\n",
    "    \"\"\"\n",
    "    # Calculate the change in distance\n",
    "    delta_distances = np.diff(distances)\n",
    "\n",
    "    # Calculate speeds as change in distance divided by change in time\n",
    "    speeds = delta_distances / dt\n",
    "\n",
    "    # Pad the speed array at the beginning with zero to maintain the same length\n",
    "    speeds = np.concatenate([np.array([speeds[0]]), speeds])\n",
    "\n",
    "    return speeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d290bac2c17940bfbc0f9296beaf70e5",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Inputs & Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e528ce19c608425292151930d380f49f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Explanation of each input and where it comes from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "6cf83a5811054461a718a71673d09aab",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 373,
    "execution_start": 1691424003628,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inputs and Required data loading\n",
    "# input varaible names are in all caps snake case\n",
    "# Whenever an input changes or is used for processing \n",
    "# the vairables are all lower in snake case\n",
    "THORAX_INDEX = 1\n",
    "\n",
    "# LFP_SPECTRAL_DF = pd.read_pickle(\"./proc/rce_pilot_2_03_spectral_bands.pkl\")\n",
    "# LFP_SPECTRAL_DF[\"video_name\"] = LFP_SPECTRAL_DF[\"video_name\"].apply(lambda x: x.strip(\".videoTimeStamps.cameraHWSync\"))\n",
    "\n",
    "# SLEAP_DIR = os.path.join(git_root, \"proc/sleap\") \n",
    "# SLEAP_DIR = \"/scratch/back_up/reward_competition_extention/final_proc/id_corrected\"\n",
    "SLEAP_DIR = \"./data\"\n",
    "\n",
    "OUTPUT_DIR = r\"./proc\" # where data is saved should always be shown in the inputs\n",
    "MED_PC_WIDTH = 29.5\n",
    "MED_PC_HEIGHT = 24\n",
    "FRAME_RATE = 22\n",
    "WINDOW_SIZE = 25\n",
    "DISTANCE_THRESHOLD = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF = pd.read_excel(\"./data/rce_pilot_3_long_comp_per_subject_start_stop_video_frame.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e3ee4891d43a4ac287413afc552ca289",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9ccbf6cc70fd4d379fa29317f733771f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe each output that the notebook creates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fc8e8920a6944918a15fac575cdf6e78",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- Is it a plot or is it data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1e639d4776a84aa9ac8ded2e14fa57db",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- How valuable is the output and why is it valuable or useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inputs and Required data loading\n",
    "# input varaible names are in all caps snake case\n",
    "# Whenever an input changes or is used for processing \n",
    "# the vairables are all lower in snake case\n",
    "OUTPUT_DIR = r\"./proc/\" # where data is saved should always be shown in the inputs\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "OUTPUT_PREFIX = \"rce_pilot_3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FULL_LFP_TRACES_PKL = \"{}_04_spectral_and_sleap.pkl\".format(OUTPUT_PREFIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8999d19b6b7d4d63bc90f0b0bd9ab085",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9b36cdf08567463082b005cb0dec684b",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe what is done to the data here and how inputs are manipulated to generate outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the videos where the subject is in the recording"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at when each subject was in each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF = START_STOP_FRAME_DF.dropna(subset=[\"file_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting the name of the SLEAP and video files where each subject was in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"sleap_name\"] = START_STOP_FRAME_DF[\"file_path\"].apply(lambda x: os.path.basename(x))\n",
    "START_STOP_FRAME_DF[\"video_name\"] = START_STOP_FRAME_DF[\"file_path\"].apply(lambda x: \".\".join(os.path.basename(x).split(\".\")[:2]))\n",
    "START_STOP_FRAME_DF[\"start_frame\"] = START_STOP_FRAME_DF[\"start_frame\"].astype(int)\n",
    "START_STOP_FRAME_DF[\"stop_frame\"] = START_STOP_FRAME_DF[\"stop_frame\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF = START_STOP_FRAME_DF.drop(columns=[\"file_path\", \"notes\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"video_name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Splitting each row into seperate row for each subject in the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"tracked_subject\"] = START_STOP_FRAME_DF[\"tracked_subject\"].apply(lambda x: str(x).split(\"_\"))\n",
    "START_STOP_FRAME_DF[\"current_subject\"] = START_STOP_FRAME_DF[\"tracked_subject\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF = START_STOP_FRAME_DF.explode(\"current_subject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in the h5 files between recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"sleap_glob\"] = START_STOP_FRAME_DF[\"sleap_name\"].apply(lambda x: glob.glob(os.path.join(SLEAP_DIR, \"**\", x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for name in START_STOP_FRAME_DF[START_STOP_FRAME_DF[\"sleap_glob\"].apply(lambda x: len(x) == 0)][\"sleap_name\"]:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF = START_STOP_FRAME_DF[START_STOP_FRAME_DF['sleap_glob'].apply(lambda x: len(x) >= 1)]\n",
    "START_STOP_FRAME_DF = START_STOP_FRAME_DF.reset_index(drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"sleap_path\"] = START_STOP_FRAME_DF[\"sleap_glob\"].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"all_sleap_data\"] = START_STOP_FRAME_DF[\"sleap_path\"].apply(lambda x: sleap.process_pose.extract_sleap_data(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"body_parts\"] = START_STOP_FRAME_DF[\"sleap_path\"].apply(lambda x: sleap.process_pose.get_node_names_from_sleap(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"body_parts\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"locations\"] = START_STOP_FRAME_DF[\"all_sleap_data\"].apply(lambda x: x[\"locations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"track_names\"] = START_STOP_FRAME_DF[\"all_sleap_data\"].apply(lambda x: x[\"track_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"locations\"].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the indexes of each subject from the track list\n",
    "START_STOP_FRAME_DF[\"subject_to_index\"] = START_STOP_FRAME_DF.apply(lambda x: {k: x[\"track_names\"].index(k) for k in x[\"tracked_subject\"] if k in x[\"track_names\"]}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"subject_to_index\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"subject_to_tracks\"] = START_STOP_FRAME_DF.apply(lambda x: {k:v for k, v in x[\"subject_to_index\"].items()}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"subject_to_tracks\"] = START_STOP_FRAME_DF.apply(lambda x: {k: x[\"locations\"][:,:,:,v] for k, v in x[\"subject_to_index\"].items()}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"subject_to_tracks\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"subject_to_tracks\"].apply(lambda x: x.keys()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the coordinates of the corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"sleap_path\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each corner file is the in the same folder and has the same basename of the pose tracking file \n",
    "START_STOP_FRAME_DF[\"corner_path\"] = START_STOP_FRAME_DF[\"sleap_path\"].apply(lambda x: x.replace(\"id_corrected.h5\", \"corner.h5\").replace(\".fixed\", \"\").replace(\".round_1\", \"\").replace(\".1_subj\", \"\").replace(\".2_subj\", \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"corner_path\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the indexes of each corner location\n",
    "START_STOP_FRAME_DF[\"corner_parts\"] = START_STOP_FRAME_DF[\"corner_path\"].apply(lambda x: sleap.process_pose.get_node_names_from_sleap(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"corner_parts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Remove this once corner files are fixed\n",
    "START_STOP_FRAME_DF = START_STOP_FRAME_DF[START_STOP_FRAME_DF[\"corner_parts\"].apply(lambda x: \"reward_port\" in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the coordinates of all the corners\n",
    "START_STOP_FRAME_DF[\"corner_to_coordinate\"] = START_STOP_FRAME_DF[\"corner_path\"].apply(lambda x: sleap.process_pose.get_sleap_tracks_from_h5(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing out each corner and creating a dictionary of name to coordinates\n",
    "START_STOP_FRAME_DF[\"corner_to_coordinate\"] = START_STOP_FRAME_DF.apply(lambda x: {part: x[\"corner_to_coordinate\"][:,index,:,:] for index, part in enumerate(x[\"corner_parts\"])}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"corner_to_coordinate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out all the Nans because there's only one labeled frame\n",
    "START_STOP_FRAME_DF[\"corner_to_coordinate\"] = START_STOP_FRAME_DF.apply(lambda x: {k: v[~np.isnan(v)][:2] for k, v in x[\"corner_to_coordinate\"].items()}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"corner_to_coordinate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the distances between corners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting the average width and height so that we can convert pixels to cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the x-coordinates for the width\n",
    "START_STOP_FRAME_DF[\"bottom_width\"] = START_STOP_FRAME_DF[\"corner_to_coordinate\"].apply(lambda x: x[\"box_bottom_right\"][0] - x[\"box_bottom_left\"][0])\n",
    "START_STOP_FRAME_DF[\"top_width\"] = START_STOP_FRAME_DF[\"corner_to_coordinate\"].apply(lambda x: x[\"box_top_right\"][0] - x[\"box_top_left\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the y-coordinates for the height\n",
    "START_STOP_FRAME_DF[\"right_height\"] = START_STOP_FRAME_DF[\"corner_to_coordinate\"].apply(lambda x: x[\"box_bottom_right\"][1] - x[\"box_top_right\"][1])\n",
    "START_STOP_FRAME_DF[\"left_height\"] = START_STOP_FRAME_DF[\"corner_to_coordinate\"].apply(lambda x: x[\"box_bottom_left\"][1] - x[\"box_top_left\"][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# averaging the width and height by adding both sides and then getting the mean\n",
    "START_STOP_FRAME_DF[\"average_height\"] = START_STOP_FRAME_DF.apply(lambda row: (row[\"right_height\"] + row[\"left_height\"])/2, axis=1)\n",
    "START_STOP_FRAME_DF[\"average_width\"] = START_STOP_FRAME_DF.apply(lambda row: (row[\"bottom_width\"] + row[\"top_width\"])/2, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getthing the pixel to cm ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"width_ratio\"] = MED_PC_WIDTH / START_STOP_FRAME_DF[\"average_width\"]\n",
    "START_STOP_FRAME_DF[\"height_ratio\"] = MED_PC_HEIGHT / START_STOP_FRAME_DF[\"average_height\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"height_ratio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"width_ratio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Pixels to cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"in_video_subjects\"] = START_STOP_FRAME_DF[\"in_video_subjects\"].apply(lambda x: x.split(\"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"subject_to_tracks\"] = START_STOP_FRAME_DF.apply(lambda x: {k: v for k, v in x[\"subject_to_tracks\"].items() if k in x[\"in_video_subjects\"]}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Converting the X-dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"subject_to_tracks\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"rescaled_locations\"] = START_STOP_FRAME_DF.apply(lambda x: {key: sleap.process_pose.fill_missing(sleap.process_pose.rescale_dimension_in_array(value, dimension=0, ratio=x[\"width_ratio\"])) for key, value in x[\"subject_to_tracks\"].items()}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Converting the Y-dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"rescaled_locations\"] = START_STOP_FRAME_DF.apply(lambda x: {key: sleap.process_pose.rescale_dimension_in_array(value, dimension=1, ratio=x[\"height_ratio\"]) for key, value in x[\"rescaled_locations\"].items()}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"corner_to_coordinate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize dictionary column\n",
    "normalized = pd.json_normalize(START_STOP_FRAME_DF[\"corner_to_coordinate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Drop the original column and concat the normalized DataFrame\n",
    "START_STOP_FRAME_DF = pd.concat([START_STOP_FRAME_DF.drop([\"corner_to_coordinate\"], axis=1), normalized], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF = START_STOP_FRAME_DF.dropna(subset=[\"reward_port\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Converting the corner coordinates into cms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for corner in START_STOP_FRAME_DF[\"corner_parts\"].iloc[0]:\n",
    "    START_STOP_FRAME_DF[corner] = START_STOP_FRAME_DF.apply(lambda x: [x[corner][0]*x[\"width_ratio\"], x[corner][1]*x[\"height_ratio\"]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking over the tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_INDEX = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"sleap_path\"].iloc[FILE_INDEX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"rescaled_locations\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(START_STOP_FRAME_DF[\"sleap_path\"].iloc[FILE_INDEX], \"r\") as f:\n",
    "    dset_names = list(f.keys())\n",
    "    current_subject = START_STOP_FRAME_DF[\"current_subject\"].iloc[FILE_INDEX]\n",
    "    locations = START_STOP_FRAME_DF[\"rescaled_locations\"].iloc[FILE_INDEX][current_subject]\n",
    "    node_names = [n.decode() for n in f[\"node_names\"][:]]\n",
    "    \n",
    "print(\"===HDF5 datasets===\")\n",
    "print(dset_names)\n",
    "print()\n",
    "\n",
    "print(\"===locations data shape===\")\n",
    "print(locations.shape)\n",
    "print()\n",
    "\n",
    "print(\"===nodes===\")\n",
    "for i, name in enumerate(node_names):\n",
    "    print(f\"{i}: {name}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thorax_loc = locations[:, THORAX_INDEX, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "plt.plot(thorax_loc[:,0],label='X-coordinates')\n",
    "# Converting to negative so that we can see both x and y track\n",
    "plt.plot(-1*thorax_loc[:,1], label='Y-coordinates')\n",
    "\n",
    "plt.legend(loc=\"center right\")\n",
    "plt.title('Thorax locations')\n",
    "plt.xlabel(\"Time in frames\")\n",
    "plt.ylabel(\"Coordinate Position\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(thorax_loc[:,0],thorax_loc[:,1])\n",
    "\n",
    "\n",
    "plt.title('Thorax tracks')\n",
    "plt.xlabel(\"X-Coordinates\")\n",
    "plt.ylabel(\"Y-Coordinates\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an individual column for each pose tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF = START_STOP_FRAME_DF.dropna(subset=\"current_subject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"agent\"] = START_STOP_FRAME_DF.apply(lambda x: list((set(x[\"tracked_subject\"]) - set([x[\"current_subject\"]]))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[START_STOP_FRAME_DF[\"agent\"].apply(lambda x: len(x) != 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"agent\"] = START_STOP_FRAME_DF[\"agent\"].apply(lambda x: x[0] if len(x) == 1 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"subject_locations\"] = START_STOP_FRAME_DF.apply(lambda x: x[\"rescaled_locations\"][x[\"current_subject\"]] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"agent_locations\"] = START_STOP_FRAME_DF.apply(lambda x: x[\"rescaled_locations\"].get(x[\"agent\"], np.nan) if x[\"agent\"] else np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting all the timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"frame_index\"] = START_STOP_FRAME_DF[\"subject_locations\"].apply(lambda x: np.arange(0, x.shape[0]) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF = START_STOP_FRAME_DF.drop([\"sleap_glob\", \"subject_to_index\", \"subject_to_tracks\", \"corner_parts\", \"corner_to_coordinate\", \"bottom_width\", \"top_width\", \"right_height\", \"left_height\", \"average_height\", \"average_width\", \"width_ratio\", \"height_ratio\", 'locations', 'track_names', 'sleap_path', 'corner_path', 'all_sleap_data', 'rescaled_locations'], errors=\"ignore\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate relavant features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features to calculate\n",
    "\n",
    "1. velocity of the mice\n",
    "2. distance between thoraxes\n",
    "3. distances to port of mice\n",
    "4. angles of orientation of mice to port\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original features to calculate\n",
    "1. distance between thoraxes\n",
    "2. velocity of mouse 1 + velocity of mouse 2\n",
    "3. | velocity of mouse 1 - velocity of mouse 2 |\n",
    "4. sum of angles of orientation of mice to port\n",
    "5. | difference of angles of orientation of mice to port |\n",
    "6. sum of distances to port of mice\n",
    "7. | differences of distances to port of mice |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting relavent body parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"body_parts\"].apply(lambda x: x.index(\"thorax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"subject_thorax\"] = START_STOP_FRAME_DF.apply(lambda x: x[\"subject_locations\"][:,x[\"body_parts\"].index(\"thorax\"),:], axis=1)\n",
    "START_STOP_FRAME_DF[\"subject_nose\"] = START_STOP_FRAME_DF.apply(lambda x: x[\"subject_locations\"][:,x[\"body_parts\"].index(\"nose\"),:], axis=1)\n",
    "START_STOP_FRAME_DF[\"subject_tail_base\"] = START_STOP_FRAME_DF.apply(lambda x: x[\"subject_locations\"][:,x[\"body_parts\"].index(\"tail_base\"),:], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"agent_thorax\"] = START_STOP_FRAME_DF.apply(lambda x: x[\"agent_locations\"][:,x[\"body_parts\"].index(\"thorax\"),:], axis=1)\n",
    "START_STOP_FRAME_DF[\"agent_nose\"] = START_STOP_FRAME_DF.apply(lambda x: x[\"agent_locations\"][:,x[\"body_parts\"].index(\"nose\"),:], axis=1)\n",
    "START_STOP_FRAME_DF[\"agent_tail_base\"] = START_STOP_FRAME_DF.apply(lambda x: x[\"subject_locations\"][:,x[\"body_parts\"].index(\"tail_base\"),:], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"subject_thorax_velocity\"] = START_STOP_FRAME_DF.apply(lambda x: compute_velocity(x[\"subject_thorax\"], window_size=FRAME_RATE*3) * FRAME_RATE, axis=1)\n",
    "START_STOP_FRAME_DF[\"subject_thorax_velocity\"] = START_STOP_FRAME_DF[\"subject_thorax_velocity\"].apply(lambda x: x.astype(np.float32) if x is not np.nan else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"agent_locations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"agent_thorax_velocity\"] = START_STOP_FRAME_DF.apply(lambda x: compute_velocity(x[\"agent_thorax\"], window_size=FRAME_RATE*3) * FRAME_RATE if x[\"agent_locations\"] is not np.nan else np.nan, axis=1)\n",
    "START_STOP_FRAME_DF[\"agent_thorax_velocity\"] = START_STOP_FRAME_DF[\"agent_thorax_velocity\"].apply(lambda x: x.astype(np.float32) if x is not np.nan else np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"subject_thorax_velocity\"].iloc[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate relavant distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. distance between thoraxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"subject_thorax_to_agent_thorax\"] = START_STOP_FRAME_DF.apply(lambda x: np.linalg.norm(x[\"subject_thorax\"] - x[\"agent_thorax\"], axis=1),  axis=1)\n",
    "START_STOP_FRAME_DF[\"subject_thorax_to_agent_thorax\"] = START_STOP_FRAME_DF[\"subject_thorax_to_agent_thorax\"].apply(lambda x: x.astype(np.float32) if x is not np.nan else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"subject_nose_to_agent_tail_base\"] = START_STOP_FRAME_DF.apply(lambda x: np.linalg.norm(x[\"subject_nose\"] - x[\"agent_tail_base\"], axis=1),  axis=1)\n",
    "START_STOP_FRAME_DF[\"subject_nose_to_agent_tail_base\"] = START_STOP_FRAME_DF[\"subject_nose_to_agent_tail_base\"].apply(lambda x: x.astype(np.float32) if x is not np.nan else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"subject_tail_base_to_agent_nose\"] = START_STOP_FRAME_DF.apply(lambda x: np.linalg.norm(x[\"subject_tail_base\"] - x[\"agent_nose\"], axis=1),  axis=1)\n",
    "START_STOP_FRAME_DF[\"subject_tail_base_to_agent_nose\"] = START_STOP_FRAME_DF[\"subject_tail_base_to_agent_nose\"].apply(lambda x: x.astype(np.float32) if x is not np.nan else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. distances to port of mice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"subject_thorax_to_reward_port\"] = START_STOP_FRAME_DF.apply(lambda x: np.linalg.norm(x[\"subject_thorax\"] - x[\"reward_port\"], axis=1),  axis=1)\n",
    "START_STOP_FRAME_DF[\"subject_thorax_to_reward_port\"] = START_STOP_FRAME_DF[\"subject_thorax_to_reward_port\"].apply(lambda x: x.astype(np.float32) if x is not np.nan else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"agent_thorax_to_reward_port\"] = START_STOP_FRAME_DF.apply(lambda x: np.linalg.norm(x[\"agent_thorax\"] - x[\"reward_port\"], axis=1) if x[\"agent_locations\"] is not np.nan else np.nan,  axis=1)\n",
    "START_STOP_FRAME_DF[\"agent_thorax_to_reward_port\"] = START_STOP_FRAME_DF[\"agent_thorax_to_reward_port\"].apply(lambda x: x.astype(np.float32) if x is not np.nan else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"subject_nose_to_reward_port\"] = START_STOP_FRAME_DF.apply(lambda x: np.linalg.norm(x[\"subject_nose\"] - x[\"reward_port\"], axis=1),  axis=1)\n",
    "START_STOP_FRAME_DF[\"subject_nose_to_reward_port\"] = START_STOP_FRAME_DF[\"subject_nose_to_reward_port\"].apply(lambda x: x.astype(np.float32) if x is not np.nan else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"agent_nose_to_reward_port\"] = START_STOP_FRAME_DF.apply(lambda x: np.linalg.norm(x[\"agent_nose\"] - x[\"reward_port\"], axis=1),  axis=1)\n",
    "START_STOP_FRAME_DF[\"agent_nose_to_reward_port\"] = START_STOP_FRAME_DF[\"agent_nose_to_reward_port\"].apply(lambda x: x.astype(np.float32) if x is not np.nan else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate to speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"subject_speed_to_reward_port\"] = START_STOP_FRAME_DF.apply(lambda x: calculate_speed_from_distances(x[\"subject_thorax_to_reward_port\"], dt),  axis=1)\n",
    "START_STOP_FRAME_DF[\"subject_speed_to_reward_port\"] = START_STOP_FRAME_DF[\"subject_speed_to_reward_port\"].apply(lambda x: x.astype(np.float32) if x is not np.nan else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"agent_speed_to_reward_port\"] = START_STOP_FRAME_DF.apply(lambda x: calculate_speed_from_distances(x[\"agent_thorax_to_reward_port\"], dt),  axis=1)\n",
    "START_STOP_FRAME_DF[\"agent_speed_to_reward_port\"] = START_STOP_FRAME_DF[\"agent_speed_to_reward_port\"].apply(lambda x: x.astype(np.float32) if x is not np.nan else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"subject_to_agent_speed\"] = START_STOP_FRAME_DF.apply(lambda x: calculate_speed_from_distances(x[\"subject_thorax_to_agent_thorax\"], dt),  axis=1)\n",
    "START_STOP_FRAME_DF[\"subject_to_agent_speed\"] = START_STOP_FRAME_DF[\"subject_to_agent_speed\"].apply(lambda x: x.astype(np.float32) if x is not np.nan else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating orientation of the mouse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. angles of orientation of mice to port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"subject_to_reward_port_angle\"] = START_STOP_FRAME_DF.apply(lambda x: calculate_time_series_angles(x[\"subject_thorax\"], x[\"subject_nose\"], np.tile(x[\"reward_port\"], (x[\"subject_nose\"].shape[0], 1))),  axis=1)\n",
    "START_STOP_FRAME_DF[\"subject_to_reward_port_angle\"] = START_STOP_FRAME_DF[\"subject_to_reward_port_angle\"].apply(lambda x: x.astype(np.float32) if x is not np.nan else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"agent_to_reward_port_angle\"] = START_STOP_FRAME_DF.apply(lambda x: calculate_time_series_angles(x[\"agent_thorax\"], x[\"agent_nose\"], np.tile(x[\"reward_port\"], (x[\"agent_nose\"].shape[0], 1))),  axis=1)\n",
    "START_STOP_FRAME_DF[\"agent_to_reward_port_angle\"] = START_STOP_FRAME_DF[\"agent_to_reward_port_angle\"].apply(lambda x: x.astype(np.float32) if x is not np.nan else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"subject_to_agent_orientation\"] = START_STOP_FRAME_DF.apply(lambda x: calculate_angles_from_arrays(x[\"subject_thorax\"], x[\"subject_nose\"], x[\"agent_thorax\"], x[\"agent_nose\"]),  axis=1)\n",
    "START_STOP_FRAME_DF[\"subject_to_agent_orientation\"] = START_STOP_FRAME_DF[\"subject_to_agent_orientation\"].apply(lambda x: x.astype(np.float32) if x is not np.nan else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making features based on social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"thorax_velocity_sum\"] = START_STOP_FRAME_DF.apply(lambda x: x[\"subject_thorax_velocity\"] + x[\"agent_thorax_velocity\"], axis=1)\n",
    "START_STOP_FRAME_DF[\"thorax_velocity_diff\"] = START_STOP_FRAME_DF.apply(lambda x: np.abs(x[\"subject_thorax_velocity\"] - x[\"agent_thorax_velocity\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"thorax_to_reward_port_sum\"] = START_STOP_FRAME_DF.apply(lambda x: x[\"subject_thorax_to_reward_port\"] + x[\"agent_thorax_to_reward_port\"], axis=1)\n",
    "START_STOP_FRAME_DF[\"thorax_to_reward_port_diff\"] = START_STOP_FRAME_DF.apply(lambda x: np.abs(x[\"subject_thorax_to_reward_port\"] - x[\"agent_thorax_to_reward_port\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"nose_to_reward_port_sum\"] = START_STOP_FRAME_DF.apply(lambda x: x[\"subject_nose_to_reward_port\"] + x[\"agent_nose_to_reward_port\"], axis=1)\n",
    "START_STOP_FRAME_DF[\"nose_to_reward_port_diff\"] = START_STOP_FRAME_DF.apply(lambda x: np.abs(x[\"subject_nose_to_reward_port\"] - x[\"agent_nose_to_reward_port\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"to_reward_port_angle_sum\"] = START_STOP_FRAME_DF.apply(lambda x: x[\"subject_to_reward_port_angle\"] + x[\"agent_to_reward_port_angle\"], axis=1)\n",
    "START_STOP_FRAME_DF[\"to_reward_port_angle_diff\"] = START_STOP_FRAME_DF.apply(lambda x: np.abs(x[\"subject_to_reward_port_angle\"] - x[\"agent_to_reward_port_angle\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"nose_to_tail_sum\"] = START_STOP_FRAME_DF.apply(lambda x: x[\"subject_tail_base_to_agent_nose\"] + x[\"subject_nose_to_agent_tail_base\"], axis=1)\n",
    "START_STOP_FRAME_DF[\"nose_to_tail_diff\"] = START_STOP_FRAME_DF.apply(lambda x: np.abs(x[\"subject_tail_base_to_agent_nose\"] - x[\"subject_nose_to_agent_tail_base\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"speed_to_reward_port_sum\"] = START_STOP_FRAME_DF.apply(lambda x: x[\"subject_speed_to_reward_port\"] + x[\"agent_speed_to_reward_port\"], axis=1)\n",
    "START_STOP_FRAME_DF[\"speed_to_reward_port_diff\"] = START_STOP_FRAME_DF.apply(lambda x: np.abs(x[\"subject_speed_to_reward_port\"] - x[\"agent_speed_to_reward_port\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # based on each subjects individually\n",
    "# features_columns = ['subject_thorax_velocity', 'agent_thorax_velocity',\n",
    "#        'subject_thorax_to_agent_thorax', 'subject_thorax_to_reward_port',\n",
    "#        'agent_thorax_to_reward_port', 'subject_to_reward_port_angle',\n",
    "#        'agent_to_reward_port_angle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on both subjects together\n",
    "features_columns = ['frame_index', 'thorax_velocity_sum', 'thorax_velocity_diff',\n",
    "       'subject_thorax_to_agent_thorax', 'thorax_to_reward_port_sum',\n",
    "       'thorax_to_reward_port_diff', 'to_reward_port_angle_sum',\n",
    "       'to_reward_port_angle_diff', 'nose_to_tail_sum', 'nose_to_tail_diff', 'subject_to_agent_orientation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on both subjects together\n",
    "features_columns = ['frame_index', 'thorax_velocity_sum', 'thorax_velocity_diff',\n",
    "       'subject_thorax_to_agent_thorax', 'thorax_to_reward_port_sum',\n",
    "       'thorax_to_reward_port_diff', 'to_reward_port_angle_sum',\n",
    "       'to_reward_port_angle_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on both subjects together\n",
    "features_columns = ['frame_index', 'thorax_velocity_sum', 'thorax_velocity_diff',\n",
    "       'thorax_to_reward_port_sum',\n",
    "       'thorax_to_reward_port_diff', 'to_reward_port_angle_sum',\n",
    "       'to_reward_port_angle_diff', 'nose_to_tail_sum', 'nose_to_tail_diff', 'subject_to_agent_orientation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on both subjects together\n",
    "features_columns = ['frame_index', \n",
    "                    'thorax_velocity_sum', \n",
    "                    'thorax_velocity_diff',\n",
    "                    'thorax_to_reward_port_sum',\n",
    "                    'thorax_to_reward_port_diff', \n",
    "                    'to_reward_port_angle_sum',\n",
    "                    'to_reward_port_angle_diff', \n",
    "                    'nose_to_tail_sum', \n",
    "                    'nose_to_tail_diff', \n",
    "                    'subject_to_agent_orientation',\n",
    "                    'subject_nose_to_reward_port',\n",
    "                    'agent_nose_to_reward_port',\n",
    "                    'speed_to_reward_port'\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on both subjects together\n",
    "features_columns = ['frame_index', \n",
    "                    'thorax_velocity_sum', \n",
    "                    'thorax_velocity_diff',\n",
    "                    'thorax_to_reward_port_sum',\n",
    "                    'thorax_to_reward_port_diff', \n",
    "                    'to_reward_port_angle_sum',\n",
    "                    'to_reward_port_angle_diff', \n",
    "                    'nose_to_tail_sum', \n",
    "                    'nose_to_tail_diff', \n",
    "                    'subject_to_agent_orientation',\n",
    "                    'nose_to_reward_port_sum',\n",
    "                    'nose_to_reward_port_diff',\n",
    "                    'speed_to_reward_port_sum',\n",
    "                    'speed_to_reward_port_diff'\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on both subjects together\n",
    "features_columns = ['frame_index', \n",
    "                    # 'thorax_velocity_sum', \n",
    "                    # 'thorax_velocity_diff',\n",
    "                    # 'thorax_to_reward_port_sum',\n",
    "                    # 'thorax_to_reward_port_diff', \n",
    "                    'to_reward_port_angle_sum',\n",
    "                    'to_reward_port_angle_diff', \n",
    "                    'nose_to_tail_sum', \n",
    "                    'nose_to_tail_diff', \n",
    "                    'subject_to_agent_orientation',\n",
    "                    'nose_to_reward_port_sum',\n",
    "                    'nose_to_reward_port_diff',\n",
    "                    'speed_to_reward_port_sum',\n",
    "                    'speed_to_reward_port_diff',\n",
    "                    'subject_to_agent_speed'\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on both subjects together\n",
    "features_columns = ['frame_index', \n",
    "                    # 'thorax_velocity_sum', \n",
    "                    # 'thorax_velocity_diff',\n",
    "                    'thorax_to_reward_port_sum',\n",
    "                    'thorax_to_reward_port_diff', \n",
    "                    # 'to_reward_port_angle_sum',\n",
    "                    # 'to_reward_port_angle_diff', \n",
    "                    'nose_to_tail_sum', \n",
    "                    'nose_to_tail_diff', \n",
    "                    # 'subject_to_agent_orientation',\n",
    "                    'nose_to_reward_port_sum',\n",
    "                    'nose_to_reward_port_diff',\n",
    "                    'speed_to_reward_port_sum',\n",
    "                    'speed_to_reward_port_diff',\n",
    "                    'subject_to_agent_speed'\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on both subjects together\n",
    "features_columns = ['frame_index',\n",
    "                    # 'subject_thorax_to_agent_thorax'\n",
    "                    'thorax_velocity_sum', \n",
    "                    'thorax_velocity_diff',\n",
    "                    'thorax_to_reward_port_sum',\n",
    "                    'thorax_to_reward_port_diff', \n",
    "                    'to_reward_port_angle_sum',\n",
    "                    'to_reward_port_angle_diff', \n",
    "                    'nose_to_tail_sum', \n",
    "                    'nose_to_tail_diff', \n",
    "                    # 'subject_to_agent_orientation',\n",
    "                    'nose_to_reward_port_sum',\n",
    "                    'nose_to_reward_port_diff',\n",
    "                    'speed_to_reward_port_sum',\n",
    "                    'speed_to_reward_port_diff',\n",
    "                    'subject_to_agent_speed'\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on both subjects together\n",
    "features_columns = ['frame_index',\n",
    "                    # Distance metrics\n",
    "                    'subject_thorax_to_agent_thorax'\n",
    "                    'thorax_to_reward_port_sum',\n",
    "                    'thorax_to_reward_port_diff',\n",
    "                    'nose_to_tail_sum', \n",
    "                    'nose_to_tail_diff',\n",
    "                    'nose_to_reward_port_sum',\n",
    "                    'nose_to_reward_port_diff',\n",
    "                    # Velocity and speed metrics\n",
    "                    'thorax_velocity_sum', \n",
    "                    'thorax_velocity_diff',\n",
    "                    'speed_to_reward_port_sum',\n",
    "                    'speed_to_reward_port_diff',\n",
    "                    'subject_to_agent_speed'\n",
    "                    # Orientation and angle\n",
    "                    'to_reward_port_angle_sum',\n",
    "                    'to_reward_port_angle_diff', \n",
    "                    'subject_to_agent_orientation',\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on both subjects together\n",
    "# features_columns = ['frame_index', 'thorax_velocity_sum', 'thorax_velocity_diff',\n",
    "#        'subject_thorax_to_agent_thorax', 'thorax_to_reward_port_sum',\n",
    "#        'thorax_to_reward_port_diff', 'to_reward_port_angle_sum',\n",
    "#        'to_reward_port_angle_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # based on each subject individually and both subjects together\n",
    "# features_columns  = ['subject_thorax_velocity',\n",
    "#        'subject_thorax_to_reward_port', 'subject_thorax_to_agent_thorax',\n",
    "#        'subject_to_reward_port_angle',\n",
    "#        'thorax_velocity_sum', 'thorax_velocity_diff',\n",
    "#        'thorax_to_reward_port_sum',\n",
    "#        'thorax_to_reward_port_diff', 'to_reward_port_angle_sum',\n",
    "#        'to_reward_port_angle_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # based on just main subject\n",
    "# features_columns = ['subject_thorax_velocity',\n",
    "#        'subject_thorax_to_reward_port', 'subject_thorax_to_agent_thorax',\n",
    "#        'subject_to_reward_port_angle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_labels = pd.read_excel(\"./data/rce_pilot_3_long_comp_per_video_trial_labels.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_labels = trial_labels.dropna(subset=[\"condition \"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_labels[\"video_name\"] = trial_labels[\"video_name\"].apply(lambda x: x.replace(\".videoTimeStamps.cameraHWSync\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"video_name\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_trial_labels_df = pd.merge(left = trial_labels, right = START_STOP_FRAME_DF, on=[\"video_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in features_columns:\n",
    "    merged_trial_labels_df[col] = merged_trial_labels_df.apply(lambda x: x[col][x[\"tone_start_frame\"]: x[\"tone_stop_frame\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_columns = [col for col in features_columns if col != \"frame_index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_trial_labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_trial_labels_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_trial_labels_df = merged_trial_labels_df.drop_duplicates(subset=[\"video_name\", \"tone_stop_frame\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_trial_labels_df = merged_trial_labels_df.dropna(subset=[\"competition_closeness\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_trial_labels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMAP Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_trial_labels_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_trial_labels_df[\"tone_frame\"] = merged_trial_labels_df.apply(lambda x: np.arange(x[\"tone_stop_frame\"] - x[\"tone_start_frame\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_columns = merged_trial_labels_df[['frame_index', \"tone_frame\", 'session_dir', 'tone_start_frame', 'reward_start',\n",
    "       'reward_dispensed', 'tone_stop_frame', 'condition ',\n",
    "       'competition_closeness', 'notes', 'experiment', \"sleap_name\", \"video_name\", \"current_subject\"] + features_columns].explode(features_columns + [\"tone_frame\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_trial_labels_df[\"subject_to_agent_orientation\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_columns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_columns[\"current_frame\"] = exploded_columns.apply(lambda x: x[\"frame_index\"][x[\"tone_frame\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_columns.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_data = exploded_columns[features_columns].values\n",
    "\n",
    "scaled_frame_data = StandardScaler().fit_transform(frame_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_embedding = umap.UMAP(random_state=42).fit_transform(scaled_frame_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterable_embedding = umap.UMAP(\n",
    "    n_neighbors=100,\n",
    "    min_dist=0,\n",
    "    n_components=2,\n",
    "    random_state=42,\n",
    ").fit_transform(scaled_frame_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans_label_zscore = cluster.KMeans(n_clusters=5, random_state=42).fit_predict(clusterable_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_label_zscore = cluster.KMeans(n_clusters=8, random_state=42).fit_predict(clusterable_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans_label_zscore = hdbscan.HDBSCAN(\n",
    "#     min_samples=100,\n",
    "#     min_cluster_size=5000,\n",
    "# ).fit_predict(clusterable_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_columns[\"kmeans_cluster\"] = kmeans_label_zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_columns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_label_zscore.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_label_zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    standard_embedding[:, 0],\n",
    "    standard_embedding[:, 1],\n",
    "    s=0.1)\n",
    "plt.gca().set_aspect('equal', 'datalim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter2 = axs[1].scatter(subsample_cluster_df['embedding_zscore_x_standard'],\n",
    "                             subsample_cluster_df['embedding_zscore_y_standard'],\n",
    "                             c=subsample_cluster_df['standard_hdbscan_labels_zscore'],\n",
    "                             s=0.1,\n",
    "                             cmap='Spectral')\n",
    "axs[1].set_title('Behavioral Clusters (standard HDBScan)')\n",
    "axs[1].legend(*scatter2.legend_elements(), bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_cluster = plt.scatter(\n",
    "    standard_embedding[:, 0],\n",
    "    standard_embedding[:, 1],\n",
    "    s=0.1,\n",
    "    c=kmeans_label_zscore,\n",
    "    cmap='Spectral')\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.legend(*umap_cluster.legend_elements())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = cm.viridis  # Choose a colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for featured in features_columns:\n",
    "    if featured == \"frame_index\":\n",
    "        continue\n",
    "    print(featured)\n",
    "    fig, ax = plt.subplots()\n",
    "    norm = Normalize(vmin=np.min(exploded_columns[featured].astype(float)), vmax=np.max(exploded_columns[featured].astype(float)))  # Normalize to the data range\n",
    "    plt.scatter(\n",
    "        standard_embedding[:, 0],\n",
    "        standard_embedding[:, 1],\n",
    "        c=exploded_columns[featured].astype(float),\n",
    "        s=0.005, cmap = cmap, norm=norm)\n",
    "\n",
    "    plt.gca().set_aspect('equal', 'datalim')\n",
    "    plt.title(featured, fontsize= 16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign each feature column to c \n",
    "scatter4 = ax[0,3].scatter(subsample_cluster_df['embedding_zscore_x_standard'],\n",
    "            subsample_cluster_df['embedding_zscore_y_standard'],\n",
    "            c=subsample_cluster_df['thorax distances'].astype(float),\n",
    "            s=0.005, cmap = 'afmhot', vmax = 400)  \n",
    "ax[0,3].set_title('Distance between mice', fontsize= 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in exploded_columns[\"kmeans_cluster\"].unique():\n",
    "    cluster_df = exploded_columns[exploded_columns[\"kmeans_cluster\"] == cluster]\n",
    "    for vid in cluster_df[\"video_name\"].unique():\n",
    "        video_df = cluster_df[cluster_df[\"video_name\"] == vid]\n",
    "        video_name = \"{}.fixed.mp4\".format(vid)\n",
    "        video_path = os.path.join(\"/scratch/back_up/reward_competition_extention/in_progress/rce3/sleap_id_correction/to_be_checked\", video_name)\n",
    "        \n",
    "        frame_numbers = video_df[\"current_frame\"].to_list()\n",
    "        Path(\"./proc/{}/{}\".format(cluster, video_name)).mkdir(parents=True, exist_ok=True)\n",
    "        extract_frames_and_make_gif(video_path, frame_numbers, \"./proc/{}/{}\".format(cluster, video_name), gif_name=\"cluster_{}_{}.gif\".format(cluster, video_name), fps=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_angle(vector_a, vector_b):\n",
    "    # Convert lists to numpy arrays if they aren't already\n",
    "    vector_a = np.array(vector_a)\n",
    "    vector_b = np.array(vector_b)\n",
    "\n",
    "    # Calculate the dot product of vectors a and b\n",
    "    dot_product = np.dot(vector_a, vector_b)\n",
    "\n",
    "    # Calculate the magnitude (norm) of vector a\n",
    "    norm_a = np.linalg.norm(vector_a)\n",
    "\n",
    "    # Calculate the magnitude (norm) of vector b\n",
    "    norm_b = np.linalg.norm(vector_b)\n",
    "\n",
    "    # Calculate the cosine of the angle between a and b\n",
    "    cos_angle = dot_product / (norm_a * norm_b)\n",
    "\n",
    "    # Calculate the angle in radians\n",
    "    angle = np.arccos(cos_angle)\n",
    "\n",
    "    # Optionally convert the angle to degrees\n",
    "    angle_degrees = np.degrees(angle)\n",
    "\n",
    "    return angle_degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle_from_points(a, b, c, d):\n",
    "    \"\"\"\n",
    "    Calculate the angle between vectors AB and CD given points A, B, C, D.\n",
    "\n",
    "    Parameters:\n",
    "    - a, b: Tuples/lists representing points A(x1, y1) and B(x2, y2).\n",
    "    - c, d: Tuples/lists representing points C(x3, y3) and D(x4, y4).\n",
    "\n",
    "    Returns:\n",
    "    - Angle in degrees between the vectors AB and CD.\n",
    "    \"\"\"\n",
    "    # Convert points to numpy arrays\n",
    "    a, b, c, d = map(np.array, [a, b, c, d])\n",
    "\n",
    "    # Compute vectors\n",
    "    ab = b - a\n",
    "    cd = d - c\n",
    "\n",
    "    # Dot product and magnitudes\n",
    "    dot_prod = np.dot(ab, cd)\n",
    "    norm_ab = np.linalg.norm(ab)\n",
    "    norm_cd = np.linalg.norm(cd)\n",
    "\n",
    "    # Calculate the angle in radians\n",
    "    cos_angle = dot_prod / (norm_ab * norm_cd)\n",
    "    angle_radians = np.arccos(cos_angle)\n",
    "\n",
    "    return angle_radians\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "a = (0, 0)\n",
    "b = (-1, 0)\n",
    "c = (0, 0)\n",
    "d = (1, 0)\n",
    "angle = calculate_angle_from_points(a, b, c, d)\n",
    "print(f\"The angle between the vectors is {angle:.2f} degrees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO: Add frame number for the video\n",
    "- Do this by making a list of frame numbers and exploding that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import numpy as np; np.random.seed(42)\n",
    "\n",
    "# Generate data x, y for scatter and an array of images.\n",
    "x = np.arange(20)\n",
    "y = np.random.rand(len(x))\n",
    "arr = np.empty((len(x),10,10))\n",
    "for i in range(len(x)):\n",
    "    f = np.random.rand(5,5)\n",
    "    arr[i, 0:5,0:5] = f\n",
    "    arr[i, 5:,0:5] =np.flipud(f)\n",
    "    arr[i, 5:,5:] =np.fliplr(np.flipud(f))\n",
    "    arr[i, 0:5:,5:] = np.fliplr(f)\n",
    "\n",
    "# create figure and plot scatter\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "line, = ax.plot(x,y, ls=\"\", marker=\"o\")\n",
    "\n",
    "# create the annotations box\n",
    "im = OffsetImage(arr[0,:,:], zoom=5)\n",
    "xybox=(50., 50.)\n",
    "ab = AnnotationBbox(im, (0,0), xybox=xybox, xycoords='data',\n",
    "        boxcoords=\"offset points\",  pad=0.3,  arrowprops=dict(arrowstyle=\"->\"))\n",
    "# add it to the axes and make it invisible\n",
    "ax.add_artist(ab)\n",
    "ab.set_visible(False)\n",
    "\n",
    "def hover(event):\n",
    "    # if the mouse is over the scatter points\n",
    "    if line.contains(event)[0]:\n",
    "        # find out the index within the array from the event\n",
    "        ind, = line.contains(event)[1][\"ind\"]\n",
    "        # get the figure size\n",
    "        w,h = fig.get_size_inches()*fig.dpi\n",
    "        ws = (event.x > w/2.)*-1 + (event.x <= w/2.) \n",
    "        hs = (event.y > h/2.)*-1 + (event.y <= h/2.)\n",
    "        # if event occurs in the top or right quadrant of the figure,\n",
    "        # change the annotation box position relative to mouse.\n",
    "        ab.xybox = (xybox[0]*ws, xybox[1]*hs)\n",
    "        # make annotation box visible\n",
    "        ab.set_visible(True)\n",
    "        # place it at the position of the hovered scatter point\n",
    "        ab.xy =(x[ind], y[ind])\n",
    "        # set the image corresponding to that point\n",
    "        im.set_data(arr[ind,:,:])\n",
    "    else:\n",
    "        #if the mouse is not over a scatter point\n",
    "        ab.set_visible(False)\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "# add callback for mouse moves\n",
    "fig.canvas.mpl_connect('motion_notify_event', hover)           \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing all necessary libraries \n",
    "import cv2 \n",
    "import os \n",
    "  \n",
    "# Read the video from specified path \n",
    "cam = cv2.VideoCapture(\"C:\\\\Users\\\\Admin\\\\PycharmProjects\\\\project_1\\\\openCV.mp4\") \n",
    "  \n",
    "try: \n",
    "      \n",
    "    # creating a folder named data \n",
    "    if not os.path.exists('data'): \n",
    "        os.makedirs('data') \n",
    "  \n",
    "# if not created then raise error \n",
    "except OSError: \n",
    "    print ('Error: Creating directory of data') \n",
    "  \n",
    "# frame \n",
    "currentframe = 0\n",
    "  \n",
    "while(True): \n",
    "      \n",
    "    # reading from frame \n",
    "    ret,frame = cam.read() \n",
    "  \n",
    "    if ret: \n",
    "        # if video is still left continue creating images \n",
    "        name = './data/frame' + str(currentframe) + '.jpg'\n",
    "        print ('Creating...' + name) \n",
    "  \n",
    "        # writing the extracted images \n",
    "        cv2.imwrite(name, frame) \n",
    "  \n",
    "        # increasing counter so that it will \n",
    "        # show how many frames are created \n",
    "        currentframe += 1\n",
    "    else: \n",
    "        break\n",
    "  \n",
    "# Release all space and windows once done \n",
    "cam.release() \n",
    "cv2.destroyAllWindows() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_strings_to_numbers(strings):\n",
    "    \"\"\"\n",
    "    Encodes an array of strings to an array of unique integers.\n",
    "\n",
    "    Parameters:\n",
    "        strings (numpy.array): Numpy array of string values.\n",
    "\n",
    "    Returns:\n",
    "        numpy.array: An array of integers where each integer represents a unique string.\n",
    "    \"\"\"\n",
    "    # Create a dictionary to map strings to numbers\n",
    "    unique_strings = np.unique(strings)\n",
    "    string_to_number = {string: idx for idx, string in enumerate(unique_strings)}\n",
    "\n",
    "    # Map the original strings to their corresponding numbers\n",
    "    number_array = np.vectorize(string_to_number.get)(strings)\n",
    "\n",
    "    return number_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_strings_to_numbers(exploded_columns[\"competition_closeness\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    standard_embedding[:, 0],\n",
    "    standard_embedding[:, 1],\n",
    "    s=0.1,\n",
    "    c=encode_strings_to_numbers(exploded_columns[\"competition_closeness\"].values),\n",
    "    cmap='Spectral')\n",
    "plt.gca().set_aspect('equal', 'datalim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Figure plotting for Paper\n",
    "plotting code for paper ready plots\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "scatter = plt.scatter(subsample_cluster_df['embedding_zscore_x_standard'],\n",
    "                             subsample_cluster_df['embedding_zscore_y_standard'],\n",
    "                             c=subsample_cluster_df['raw_kmeans_labels_zscore'],\n",
    "                             s=0.1,\n",
    "                             cmap='Spectral')\n",
    "plt.title('Behavior Clusters', fontsize = 24)\n",
    "legend = plt.legend(*scatter.legend_elements(),\n",
    "                    bbox_to_anchor=(.94, 1),\n",
    "                    frameon = False,\n",
    "                    fontsize = 22,\n",
    "                    markerscale = 2,\n",
    "                    ncol = 1,\n",
    "                    handletextpad = -0.2,\n",
    "                    columnspacing = 0.2)\n",
    "plt.gca().spines['top'].set_linewidth(2)\n",
    "plt.gca().spines['right'].set_linewidth(2)\n",
    "plt.gca().spines['bottom'].set_linewidth(2)\n",
    "plt.gca().spines['left'].set_linewidth(2)\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_first = True\n",
    "recording_labels = []\n",
    "frame_indice_labels = []\n",
    "\n",
    "for file, recording in info.items():\n",
    "    #creating arrays for recording name, strain, frame indice, \n",
    "    # and trial indice (0 for iti, 0-10 for tone) that are as long as there are frames \n",
    "    recording_labels += [file] * recording.locations.shape[0]\n",
    "    file_row = tone_times_df[tone_times_df['File Name'] == file]\n",
    "\n",
    "    frame_indice_labels = np.concatenate([frame_indice_labels,np.arange(0, recording.locations.shape[0])], axis = 0)\n",
    "    temp_trial_indices = np.zeros(recording.locations.shape[0])\n",
    "    #loading in normalization_factor since not all the videos are the same size / resolution\n",
    "    distance_normalization_factor = box_setup[file]['distance_normalization_factor']\n",
    "    #loading in reward_point (x,y)\n",
    "    reward_port = box_setup[file]['reward_port']\n",
    "    #creating the tone snippets from 0-10 for the frames during the tone\n",
    "    for trial in recording.tones:\n",
    "        try:\n",
    "            temp_trial_indices[trial:trial+trial_length] = np.linspace(0,10,300)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    if is_first:\n",
    "        trial_indices = temp_trial_indices\n",
    "    else: \n",
    "        trial_indices = np.concatenate([trial_indices, temp_trial_indices])\n",
    "\n",
    "    if is_first:\n",
    "        features = np.stack([f1, f2, f3, f6, f7, f8, f9])\n",
    "    else:\n",
    "        temp_features =  np.stack([f1, f2, f3, f6, f7, f8, f9])\n",
    "        features = np.concatenate([features,temp_features], axis = 1)\n",
    "    is_first = False\n",
    "recording_labels = np.array(recording_labels)\n",
    "strain_labels = np.array(strain_labels)\n",
    "zscored_features = []\n",
    "# z score each feature \n",
    "for i in range(features.shape[0]):\n",
    "    mean = np.mean(features[i])\n",
    "    std_dev = np.std(features[i])\n",
    "    normalized = (features[i]-mean)/std_dev\n",
    "    zscored_features.append(normalized)\n",
    "# stack zscored features onto the feature calculations \n",
    "features = np.concatenate([features, np.stack(zscored_features)], axis = 0)\n",
    "# name features \n",
    "feature_names = ['thorax distances', 'mouse velocity sum',\n",
    "                'mouse velocity diff', \n",
    "                #'orientation b/w mice sum',\n",
    "                #'orientation b/w mice diff', \n",
    "                'orientation to port sum',\n",
    "                'orientation to port diff',\n",
    "                'distance to port sum',\n",
    "                'distance to port diff']\n",
    "#name z score features feature name + _zscore\n",
    "for name in range(len(feature_names)):\n",
    "    zscore_name = feature_names[name]+'_zscore'\n",
    "    feature_names.append(zscore_name)\n",
    "#name the non-feature columns\n",
    "new_columns = ['Strain',\n",
    "               'Recording',\n",
    "               'frame indice',\n",
    "               'trial_indice',\n",
    "               'tube_test_elo',\n",
    "               'urine_marking_elo',\n",
    "               'home_cage_observation_elo',\n",
    "               'reward_comp_elo']\n",
    "# add both lists to create a master list of all column names \n",
    "column_names = feature_names + new_columns\n",
    "# appen them all into an array of features as columns and frames as rows\n",
    "data = np.column_stack([features.T, \n",
    "                        recording_labels[:, None],\n",
    "                        frame_indice_labels[:, None],\n",
    "                        trial_indices[:,None],\n",
    "# turn array into a Dataframe\n",
    "df = pd.DataFrame(data, columns = column_names)\n",
    "reduced_frames = len(df) \n",
    "#and subsample for every third frame (otherwise my computer crashes)\n",
    "every_third_index = np.arange(0, reduced_frames, 3)\n",
    "subsample_df = df.iloc[every_third_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_first = True\n",
    "recording_labels = []\n",
    "frame_indice_labels = []\n",
    "strain_labels = []\n",
    "tube_test_elo_labels = []\n",
    "urine_marking_elo_labels = []\n",
    "home_cage_observation_elo_labels = []\n",
    "reward_comp_elo_labels = []\n",
    "#trial length = 30 fps * 10 second tone\n",
    "trial_length = 10*30\n",
    "for file, recording in info.items():\n",
    "    #creating arrays for recording name, strain, frame indice, \n",
    "    # and trial indice (0 for iti, 0-10 for tone) that are as long as there are frames \n",
    "    recording_labels += [file] * recording.locations.shape[0]\n",
    "    strain_labels += [recording.strain] * recording.locations.shape[0]\n",
    "    file_row = tone_times_df[tone_times_df['File Name'] == file]\n",
    "    # grab elo score information\n",
    "    if not file_row.empty:\n",
    "        tube_test_elo_diff = file_row['tube_test_RD'].values[0]\n",
    "        urine_marking_elo_diff = file_row['urine_marking_RD'].values[0]\n",
    "        home_cage_elo_diff = file_row['home_cage_observation_RD'].values[0]\n",
    "        reward_comp_elo_diff = file_row['reward_comp_RD'].values[0]\n",
    "    else:\n",
    "        tube_test_elo_diff = 0\n",
    "        urine_marking_elo_diff = 0\n",
    "        home_cage_elo_diff = 0\n",
    "        reward_comp_elo_diff = 0\n",
    "    #create arrays of length num_frames    \n",
    "    tube_test_elo_labels += [tube_test_elo_diff] * recording.locations.shape[0]\n",
    "    urine_marking_elo_labels += [urine_marking_elo_diff] * recording.locations.shape[0]\n",
    "    home_cage_observation_elo_labels += [home_cage_elo_diff] * recording.locations.shape[0]\n",
    "    reward_comp_elo_labels += [reward_comp_elo_diff] * recording.locations.shape[0]\n",
    "    #turn all lists into np. arrays for concatenating and other functions\n",
    "    tube_test_elo_array = np.array(tube_test_elo_labels)\n",
    "    urine_marking_elo_array = np.array(urine_marking_elo_labels)\n",
    "    home_cage_observation_elo_array = np.array(home_cage_observation_elo_labels)\n",
    "    reward_comp_elo_array = np.array(reward_comp_elo_labels)\n",
    "    frame_indice_labels = np.concatenate([frame_indice_labels,np.arange(0, recording.locations.shape[0])], axis = 0)\n",
    "    temp_trial_indices = np.zeros(recording.locations.shape[0])\n",
    "    #loading in normalization_factor since not all the videos are the same size / resolution\n",
    "    distance_normalization_factor = box_setup[file]['distance_normalization_factor']\n",
    "    #loading in reward_point (x,y)\n",
    "    reward_port = box_setup[file]['reward_port']\n",
    "    #creating the tone snippets from 0-10 for the frames during the tone\n",
    "    for trial in recording.tones:\n",
    "        try:\n",
    "            temp_trial_indices[trial:trial+trial_length] = np.linspace(0,10,300)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    if is_first:\n",
    "        trial_indices = temp_trial_indices\n",
    "    else: \n",
    "        trial_indices = np.concatenate([trial_indices, temp_trial_indices])\n",
    "    # features 1 - 2 distance between thoraxes and noses\n",
    "    f1 = recording.distances_between_mice('thorax', distance_normalization_factor) # distances between mice works \n",
    "    #features 3-4: velocities of each mouse\n",
    "    velocities = recording.node_velocity('thorax', normalization_factor = distance_normalization_factor)\n",
    "    f2 = velocities[0] + velocities[1]# this one is from sleap so assuming this works\n",
    "    f3 = np.abs(velocities[0] - velocities[1])\n",
    "    #feature 5: angle of orientation between mice, 2pi is facing each other\n",
    "    # 0 radians is not facing each other (or parallel)\n",
    "    #orientations = recording.orientation()\n",
    "    #f4 = orientations[0] + orientations [1]# this works\n",
    "    #f5 = np.abs(orientations[0] - orientations [1])\n",
    "    #feature 6-7: angle from nose to forehead to reward port\n",
    "    angle_to_port = recording.point_angles('nose', 'thorax', reward_port)\n",
    "    distance_to_port = recording.distances_to_point('nose', reward_port, distance_normalization_factor)\n",
    "    f6 = angle_to_port[0] + angle_to_port[1]# this works with thorax\n",
    "    f7 = np.abs(angle_to_port[0] - angle_to_port[1])\n",
    "    #feature 8-9: distance to reward point for each mosue\n",
    "    f8 = distance_to_port[0] + distance_to_port[1] # this works\n",
    "    f9 = np.abs(distance_to_port[0] - distance_to_port[1])\n",
    "    #add calculated features into a multidimensional array \n",
    "    # n columns for each feature, rows are calculations per frame\n",
    "    if is_first:\n",
    "        features = np.stack([f1, f2, f3, f6, f7, f8, f9])\n",
    "    else:\n",
    "        temp_features =  np.stack([f1, f2, f3, f6, f7, f8, f9])\n",
    "        features = np.concatenate([features,temp_features], axis = 1)\n",
    "    is_first = False\n",
    "recording_labels = np.array(recording_labels)\n",
    "strain_labels = np.array(strain_labels)\n",
    "zscored_features = []\n",
    "# z score each feature \n",
    "for i in range(features.shape[0]):\n",
    "    mean = np.mean(features[i])\n",
    "    std_dev = np.std(features[i])\n",
    "    normalized = (features[i]-mean)/std_dev\n",
    "    zscored_features.append(normalized)\n",
    "# stack zscored features onto the feature calculations \n",
    "features = np.concatenate([features, np.stack(zscored_features)], axis = 0)\n",
    "# name features \n",
    "feature_names = ['thorax distances', 'mouse velocity sum',\n",
    "                'mouse velocity diff', \n",
    "                #'orientation b/w mice sum',\n",
    "                #'orientation b/w mice diff', \n",
    "                'orientation to port sum',\n",
    "                'orientation to port diff',\n",
    "                'distance to port sum',\n",
    "                'distance to port diff']\n",
    "#name z score features feature name + _zscore\n",
    "for name in range(len(feature_names)):\n",
    "    zscore_name = feature_names[name]+'_zscore'\n",
    "    feature_names.append(zscore_name)\n",
    "#name the non-feature columns\n",
    "new_columns = ['Strain',\n",
    "               'Recording',\n",
    "               'frame indice',\n",
    "               'trial_indice',\n",
    "               'tube_test_elo',\n",
    "               'urine_marking_elo',\n",
    "               'home_cage_observation_elo',\n",
    "               'reward_comp_elo']\n",
    "# add both lists to create a master list of all column names \n",
    "column_names = feature_names + new_columns\n",
    "# appen them all into an array of features as columns and frames as rows\n",
    "data = np.column_stack([features.T, \n",
    "                        strain_labels[:, None],\n",
    "                        recording_labels[:, None],\n",
    "                        frame_indice_labels[:, None],\n",
    "                        trial_indices[:,None],\n",
    "                        tube_test_elo_array[:, None],\n",
    "                        urine_marking_elo_array[:, None],\n",
    "                        home_cage_observation_elo_array[:, None],\n",
    "                        reward_comp_elo_array[:,None]])\n",
    "# turn array into a Dataframe\n",
    "df = pd.DataFrame(data, columns = column_names)\n",
    "reduced_frames = len(df) \n",
    "#and subsample for every third frame (otherwise my computer crashes)\n",
    "every_third_index = np.arange(0, reduced_frames, 3)\n",
    "subsample_df = df.iloc[every_third_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting together LFP and video start/stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"video_name\"].unique()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LFP_SPECTRAL_DF[\"video_name\"].unique()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LFP_SPECTRAL_DF[\"current_subject\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"current_subject\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF = pd.merge(LFP_SPECTRAL_DF, START_STOP_FRAME_DF, on=[\"video_name\", \"current_subject\"], how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF[\"video_timestamps\"].apply(lambda x: x.shape).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Checking if any of the velocities contain Nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF[LFP_AND_SLEAP_DF[\"subject_thorax_velocity\"].apply(lambda x: np.isnan(x).any())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FULL_LFP_TRACES_PKL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF.to_pickle(os.path.join(OUTPUT_DIR, FULL_LFP_TRACES_PKL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in LFP_AND_SLEAP_DF.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "cf8fe3695d074ee7887fdf6459cbf5ce",
  "kernelspec": {
   "display_name": "mountainsort_0_5_6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
